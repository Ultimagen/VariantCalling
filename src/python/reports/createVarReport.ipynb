{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variant Calling Report v1.2.1\n",
    "## Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nexusplt as nxp\n",
    "from configparser import ConfigParser\n",
    "\n",
    "pd.options.display.float_format = '{:,.2%}'.format\n",
    "\n",
    "configFile='var_report.config'\n",
    "parser = ConfigParser()\n",
    "parser.read(configFile)\n",
    "\n",
    "prmNames=['run_id',\n",
    "          'h5_concordance_file', 'h5_model_file'\n",
    "         ]\n",
    "\n",
    "prm={}\n",
    "for name in prmNames:\n",
    "    prm[name]=parser.get('VarReport', name)\n",
    "\n",
    "h5outfile = parser.get('VarReport', 'h5_output', fallback='var_report.h5')\n",
    "imgpref = parser.get('VarReport', 'image_output_prefix', fallback=prm['run_id']+'.vars')+'.'\n",
    "imgdir = 'plots'\n",
    "\n",
    "sources = {'Default':(prm['h5_concordance_file'],\"concordance\"),\n",
    "           'Trained':(prm['h5_model_file'],\"scored_concordance\")\n",
    "          }\n",
    "\n",
    "data = {}\n",
    "for s in sources:\n",
    "    data[s]={}\n",
    "    d=pd.read_hdf(sources[s][0], key=sources[s][1], mode='r')\n",
    "    data[s]=d\n",
    "\n",
    "\n",
    "prm['mean_var_depth']='{:.2f}'.format(data['Default']['well_mapped_coverage'].mean())\n",
    "prmNames.append('mean_var_depth')\n",
    "   \n",
    "try:\n",
    "    args=pd.read_hdf(sources['Default'][0], 'input_args', mode='r')\n",
    "    prm['truth_sample_name']=args['truth_sample_name'][0]\n",
    "except:\n",
    "    prm['truth_sample_name']=parser.get('VarReport', 'truth_sample_name', fallback='NA')\n",
    "prmNames.append('truth_sample_name')\n",
    "\n",
    "\n",
    "prmdf = pd.DataFrame.from_dict(prm, orient='index',columns=['value']).reindex(prmNames)\n",
    "prmdf.to_hdf(h5outfile, key=\"parameters\")\n",
    "prmdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterByCategory(data,cat):\n",
    "    if cat=='SNP':\n",
    "        return data[data['indel']==False]\n",
    "    elif cat=='non-hmer Indel':\n",
    "        return data[(data['indel']==True) & (data['hmer_indel_length']==0) & (data['indel_length']>0)]\n",
    "    elif cat=='non-hmer Indel w/o LCR':\n",
    "        return data[(data['indel']==True) & (data['hmer_indel_length']==0) & (data['indel_length']>0) & \n",
    "                    (~data['LCR-hs38'])]\n",
    "    elif cat=='hmer Indel <=4':\n",
    "        return data[(data['indel']==True) & (data['hmer_indel_length']>0) & (data['hmer_indel_length']<=4)]\n",
    "    elif cat=='hmer Indel >4,<=8':\n",
    "        return data[(data['indel']==True) & (data['hmer_indel_length']>4) & (data['hmer_indel_length']<=8)]\n",
    "    elif cat=='hmer Indel >8,<=10':\n",
    "        return data[(data['indel']==True) & (data['hmer_indel_length']>8) & (data['hmer_indel_length']<=10)]\n",
    "    for i in range (1,10):\n",
    "        if cat=='hmer Indel {0:d}'.format(i):\n",
    "            return data[(data['indel']==True) & (data['hmer_indel_length']==i)]\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcPerformance(data, gt=False):\n",
    "    classify='classify_gt' if gt else 'classify'\n",
    "    \n",
    "    d=data.copy()\n",
    "    d['tree_score'] = np.where(d[classify]=='fn',-1,d['tree_score'])\n",
    "    d=d[[classify,'tree_score']].sort_values(by=['tree_score'])\n",
    "    d['label'] = np.where(d[classify]=='fp',0,1)\n",
    "\n",
    "    num=len(d)\n",
    "    numPos=sum(d['label'])\n",
    "    numNeg=num-numPos\n",
    "    if num<10:\n",
    "        return (pd.DataFrame(),None,numPos,numNeg)\n",
    "    \n",
    "    d['fn']=np.cumsum(d['label'])\n",
    "    d['tp']=numPos-(d['fn'])\n",
    "    d['fp']=numNeg-np.cumsum(1-d['label'])\n",
    "\n",
    "    d['recall']=d['tp']/(d['tp']+d['fn'])\n",
    "    d['precision']=d['tp']/(d['tp']+d['fp'])\n",
    "\n",
    "    d['f1']=d['tp']/(d['tp']+0.5*d['fn']+0.5*d['fp'])\n",
    "\n",
    "    d['mask']=((d['tp']+d['fn'])>=20) & ((d['tp']+d['fp'])>=20) & (d['tree_score']>=0)\n",
    "    if len(d[d['mask']])==0:\n",
    "        return (pd.DataFrame(),None,numPos,numNeg)\n",
    "    \n",
    "    maxF1=max(d[d['mask']]['f1'])\n",
    "    d['opt']=(d['f1']==maxF1)\n",
    "\n",
    "    return (d[['recall','precision']][d['mask']],\n",
    "            d[['recall','precision','f1']][d['opt'] & d['mask']],\n",
    "            numPos,numNeg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPerformance(perfCurve,optRes,categories,ext=None,img=None):\n",
    "    n=len(categories)\n",
    "    fig, ax = plt.subplots(1,n,figsize=(4*n,4))\n",
    "    col=['r','b','g','m','k']\n",
    "\n",
    "    for i,cat in enumerate(categories):\n",
    "        for j,s in enumerate(sources):\n",
    "            perf=perfCurve[s][cat]\n",
    "            opt=optRes[s][cat]\n",
    "            if not perf.empty:\n",
    "                ax[i].plot(perf.recall,perf.precision,'-',label=s,color=col[j])    \n",
    "                ax[i].plot(opt.recall,opt.precision,'o',color=col[j])\n",
    "            title=cat if ext==None else '{0} ({1})'.format(cat,ext)\n",
    "            ax[i].set_title(title)\n",
    "            ax[i].set_xlabel(\"Recall\")\n",
    "            ax[i].set_xlim([0.4,1])\n",
    "            ax[i].set_ylim([0.4,1])\n",
    "            ax[i].grid(True)\n",
    "\n",
    "    ax[0].set_ylabel(\"Precision\")\n",
    "    ax[0].legend(loc='lower left')\n",
    "    \n",
    "    if img:\n",
    "        nxp.save(fig,imgpref+img,'png',outdir=imgdir)\n",
    "    \n",
    "    \n",
    "def getPerformance(data,categories,gt=False):\n",
    "    optTab={}\n",
    "    optRes={}\n",
    "    perfCurve={}\n",
    "    for s in sources:\n",
    "        optTab[s]=pd.DataFrame()\n",
    "        optRes[s]={}\n",
    "        perfCurve[s]={}\n",
    "\n",
    "        for i,cat in enumerate(categories):\n",
    "            d=filterByCategory(data[s],cat)\n",
    "            perf,opt,pos,neg=calcPerformance(d,gt)\n",
    "            perfCurve[s][cat]=perf\n",
    "            optRes[s][cat]=opt\n",
    "            \n",
    "            row=pd.DataFrame({'# pos':pos,\n",
    "                              '# neg':neg,\n",
    "                              'max recall':np.nan if perf.empty else max(perf.recall),\n",
    "                              'recall':np.nan if perf.empty else opt.recall[0],\n",
    "                              'precision':np.nan if perf.empty else opt.precision[0],\n",
    "                              'F1':np.nan if perf.empty else opt.f1[0]\n",
    "                             },index=[cat])\n",
    "            optTab[s]=pd.concat([optTab[s],row])\n",
    "            \n",
    "    return optTab,optRes,perfCurve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance: all Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=['SNP','non-hmer Indel','non-hmer Indel w/o LCR','hmer Indel <=4','hmer Indel >4,<=8']\n",
    "optTab1,optRes,perfCurve=getPerformance(data,categories)\n",
    "plotPerformance(perfCurve,optRes,categories,img='all.primary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=['hmer Indel 4','hmer Indel 5','hmer Indel 6','hmer Indel 7','hmer Indel 8','hmer Indel >8,<=10']\n",
    "optTab2,optRes,perfCurve=getPerformance(data,categories)\n",
    "plotPerformance(perfCurve,optRes,categories,img='all.hmers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.2%}'.format\n",
    "\n",
    "optTab={}\n",
    "for s in sources:\n",
    "    optTab[s]=pd.concat([optTab1[s], optTab2[s]])\n",
    "df=pd.concat([optTab[s] for s in sources], axis=1, keys=[s for s in sources])\n",
    "df.to_hdf(h5outfile, key=\"all_data\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Including genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=['SNP','non-hmer Indel','non-hmer Indel w/o LCR','hmer Indel <=4','hmer Indel >4,<=8']\n",
    "optTab,optRes,perfCurve=getPerformance(data,categories,gt=True)\n",
    "plotPerformance(perfCurve,optRes,categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([optTab[s] for s in sources], axis=1, keys=[s for s in sources])\n",
    "df.to_hdf(h5outfile, key=\"all_data_gt\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance: cvg>=20, mappability.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtData={}\n",
    "for s in sources:\n",
    "    d=data[s]\n",
    "    filtData[s]=d[(d['well_mapped_coverage']>=20) &\n",
    "                  (d['mappability.0'])\n",
    "                 ]\n",
    "\n",
    "categories=['SNP','non-hmer Indel','non-hmer Indel w/o LCR','hmer Indel <=4','hmer Indel >4,<=8']\n",
    "optTab1,optRes,perfCurve=getPerformance(filtData,categories)\n",
    "plotPerformance(perfCurve,optRes,categories,img='hicvg.primary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=['hmer Indel 4','hmer Indel 5','hmer Indel 6','hmer Indel 7','hmer Indel 8','hmer Indel >8,<=10']\n",
    "optTab2,optRes,perfCurve=getPerformance(filtData,categories)\n",
    "plotPerformance(perfCurve,optRes,categories,img='hicvg.hmers')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optTab={}\n",
    "for s in sources:\n",
    "    optTab[s]=pd.concat([optTab1[s], optTab2[s]])\n",
    "df=pd.concat([optTab[s] for s in sources], axis=1, keys=[s for s in sources])\n",
    "df.to_hdf(h5outfile, key=\"good_cvg_data\")\n",
    "defTable=df.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Including genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=['SNP','non-hmer Indel','non-hmer Indel w/o LCR','hmer Indel <=4','hmer Indel >4,<=8']\n",
    "optTab,optRes,perfCurve=getPerformance(filtData,categories,gt=True)\n",
    "plotPerformance(perfCurve,optRes,categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([optTab[s] for s in sources], axis=1, keys=[s for s in sources])\n",
    "df.to_hdf(h5outfile, key=\"good_cvg_data_gt\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### per base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=['SNP','hmer Indel <=4','hmer Indel >4,<=8','hmer Indel >8,<=10','hmer Indel 8']\n",
    "\n",
    "baseData={}\n",
    "b =('A','T')\n",
    "for s in sources:\n",
    "        d=filtData[s]\n",
    "        baseData[s]=d[((d['indel']==False) & ((d['ref']==b[0]) | (d['ref']==b[1]))) |\n",
    "                      ((d['hmer_indel_length']>0) & ((d['hmer_indel_nuc']==b[0]) | (d['hmer_indel_nuc']==b[1])))\n",
    "                     ]\n",
    "optTab1,optRes,perfCurve=getPerformance(baseData,categories)\n",
    "for s in sources:\n",
    "    optTab1[s].rename(index={a:'{0} ({1}/{2})'.format(a,b[0],b[1]) for a in optTab1[s].index}, inplace=True)\n",
    "plotPerformance(perfCurve,optRes,categories,'A/T')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=['SNP','hmer Indel <=4','hmer Indel >4,<=8','hmer Indel >8,<=10','hmer Indel 6']\n",
    "baseData={}\n",
    "b =('C','G')\n",
    "for s in sources:\n",
    "        d=filtData[s]\n",
    "        baseData[s]=d[((d['indel']==False) & ((d['ref']==b[0]) | (d['ref']==b[1]))) |\n",
    "                      ((d['hmer_indel_length']>0) & ((d['hmer_indel_nuc']==b[0]) | (d['hmer_indel_nuc']==b[1])))\n",
    "                     ]\n",
    "optTab2,optRes,perfCurve=getPerformance(baseData,categories)\n",
    "for s in sources:\n",
    "    optTab2[s].rename(index={a:'{0} ({1}/{2})'.format(a,b[0],b[1]) for a in optTab2[s].index}, inplace=True)\n",
    "plotPerformance(perfCurve,optRes,categories,'C/G')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optTab={}\n",
    "for s in sources:\n",
    "    optTab[s]=pd.concat([optTab1[s], optTab2[s]])\n",
    "df=pd.concat([optTab[s] for s in sources], axis=1, keys=[s for s in sources])\n",
    "df.to_hdf(h5outfile, key=\"per_base_data\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib agg\n",
    "d=defTable['Trained'][['max recall','recall','precision']]\n",
    "labels=['SNP','nhmer','nhmer w/o LCR','hmer 2-4','hmer 5-8','hmer 4','hmer 5','hmer 6','hmer 7','hmer 8','hmer 9-10']\n",
    "fig=plt.figure()\n",
    "ax=d.plot()\n",
    "plt.xticks(np.arange(len(d.index)), rotation=30, ha='right')\n",
    "ax.set_xticklabels(labels)\n",
    "plt.ylim([0.4,1.05])\n",
    "plt.grid()\n",
    "plt.title('Cvg>20X, Trained variant calls')\n",
    "plt.tight_layout()\n",
    "nxp.save(fig,imgpref+'summary','png',outdir=imgdir)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
