{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variant Calling Report v1.2.6\n",
    "## 1. Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-25T13:41:08.009132Z",
     "start_time": "2022-07-25T13:41:06.919618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: mpld3 not available\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nexusplt as nxp\n",
    "from configparser import ConfigParser\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "pd.options.display.float_format = '{:,.2%}'.format\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-25T13:41:08.938665Z",
     "start_time": "2022-07-25T13:41:08.864530Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "configFile='var_report.config'\n",
    "parser = ConfigParser()\n",
    "parser.read(configFile)\n",
    "\n",
    "prmNames=['run_id','pipeline_version', \n",
    "          'h5_concordance_file',\n",
    "          'model_name_with_gt','model_name_without_gt',\n",
    "          'model_pkl_with_gt','model_pkl_without_gt'\n",
    "         ]\n",
    "prm = {p: parser.get('VarReport', p) for p in prmNames}\n",
    "reference_version = parser.get('VarReport', 'reference_version', fallback='hg38')\n",
    "prm['reference_version'] = reference_version\n",
    "\n",
    "# Optional parameters\n",
    "h5outfile = parser.get('VarReport', 'h5_output', fallback='var_report.h5')\n",
    "imgpref = parser.get('VarReport', 'image_output_prefix', fallback=prm['run_id']+'.vars')+'.'\n",
    "\n",
    "imgdir = 'plots'\n",
    "\n",
    "sources = {'Trained wo gt': (prm['h5_concordance_file'], \"concordance\")}\n",
    "data    = {'Trained wo gt': pd.read_hdf(prm['h5_concordance_file'], key=\"concordance\", mode='r')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-25T13:41:11.945866Z",
     "start_time": "2022-07-25T13:41:11.910842Z"
    }
   },
   "outputs": [],
   "source": [
    "if reference_version == \"hg38\":\n",
    "    columns_to_select = ['indel','hmer_indel_length', 'tree_score',\n",
    "                     'filter','blacklst', 'classify','classify_gt',\n",
    "                     'indel_length','hmer_indel_nuc','ref',\n",
    "                     'gt_ground_truth','well_mapped_coverage','mappability.0','ug_hcr','LCR-hs38']\n",
    "    rename_dict = {'LCR-hs38':'LCR'}\n",
    "elif reference_version == \"hg19\":\n",
    "        columns_to_select = ['indel','hmer_indel_length', 'tree_score',\n",
    "                         'filter','blacklst', 'classify','classify_gt',\n",
    "                         'indel_length','hmer_indel_nuc','ref',\n",
    "                         'gt_ground_truth','well_mapped_coverage', 'LCR-hg19_tab_no_chr', \n",
    "                             'mappability.hg19.0_tab_no_chr','ug_hcr_hg19_no_chr']\n",
    "        rename_dict = {'LCR-hg19_tab_no_chr':'LCR', \n",
    "                       'mappability.hg19.0_tab_no_chr':'mappability.0',\n",
    "                       'ug_hcr_hg19_no_chr':'ug_hcr'}\n",
    "\n",
    "# Load the concordance data for the entire genome\n",
    "with pd.HDFStore(prm['h5_concordance_file']) as hdf:\n",
    "    keys=hdf.keys()\n",
    "    wg_dfs = []\n",
    "    for k in keys: \n",
    "        if k in ['/concordance','/input_args']:\n",
    "            continue\n",
    "        else:\n",
    "            tmp = pd.read_hdf(hdf,k)\n",
    "            tmp = tmp[[ x for x in columns_to_select if x in tmp.columns]]\n",
    "            wg_dfs.append(tmp)\n",
    "    wg_df=pd.concat(wg_dfs)\n",
    "    wg_df.rename(columns=rename_dict,inplace=True)\n",
    "\n",
    "for s in sources: \n",
    "    data[s]=data[s].rename(columns=rename_dict)\n",
    "data['whole genome'] = wg_df\n",
    "\n",
    "sources['whole genome'] = (prm['h5_concordance_file'],\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'well_mapped_coverage' in data['whole genome'].columns:\n",
    "    prm['mean_var_depth']='{:.2f}'.format(data['whole genome']['well_mapped_coverage'].mean())\n",
    "    prmNames.append('mean_var_depth')\n",
    "   \n",
    "try:\n",
    "    args=pd.read_hdf(sources['Trained wo gt'][0], 'input_args', mode='r')\n",
    "    prm['truth_sample_name']=args['truth_sample_name'][0]\n",
    "except:\n",
    "    prm['truth_sample_name']=parser.get('VarReport', 'truth_sample_name', fallback='NA')\n",
    "prmNames.append('truth_sample_name')\n",
    "\n",
    "\n",
    "prmdf = pd.DataFrame.from_dict(prm, orient='index',columns=['value']).reindex(prmNames)\n",
    "prmdf.to_hdf(h5outfile, key=\"parameters\")\n",
    "\n",
    "prmdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def filterByCategory(data,cat):\n",
    "    if cat=='SNP':\n",
    "        return data[data['indel']==False]\n",
    "    if cat=='Indel':\n",
    "        return data[data['indel']==True]\n",
    "    elif cat=='non-hmer Indel':\n",
    "        return data[(data['indel']==True) & (data['hmer_indel_length']==0) & (data['indel_length']>0)]\n",
    "    elif cat=='non-hmer Indel w/o LCR':\n",
    "        return data[(data['indel']==True) & (data['hmer_indel_length']==0) & (data['indel_length']>0) & \n",
    "                    (~data['LCR'])]\n",
    "    elif cat=='hmer Indel <=4':\n",
    "        return data[(data['indel']==True) & (data['hmer_indel_length']>0) & (data['hmer_indel_length']<=4)]\n",
    "    elif cat=='hmer Indel >4,<=8':\n",
    "        return data[(data['indel']==True) & (data['hmer_indel_length']>4) & (data['hmer_indel_length']<=8)]\n",
    "    elif cat=='hmer Indel >8,<=10':\n",
    "        return data[(data['indel']==True) & (data['hmer_indel_length']>8) & (data['hmer_indel_length']<=10)]\n",
    "    for i in range (1,10):\n",
    "        if cat=='hmer Indel {0:d}'.format(i):\n",
    "            return data[(data['indel']==True) & (data['hmer_indel_length']==i)]\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calcPerformance(data):\n",
    "    classify_col='classify_gt' \n",
    "    d=data.copy()\n",
    "    \n",
    "    # Change tree_score such that PASS will get high score values. FNs will be the lowest\n",
    "    score_pass = d.query('filter==\"PASS\" & tree_score==tree_score').head(20)['tree_score'].mean()\n",
    "    score_not_pass = d.query('filter!=\"PASS\" & tree_score==tree_score').head(20)['tree_score'].mean()\n",
    "    dir_switch = 1 if score_pass>score_not_pass else -1\n",
    "    score = d['tree_score'] * dir_switch\n",
    "    score = score - score.min()\n",
    "    d['tree_score'] = np.where(d[classify_col]=='fn', -1, score)    \n",
    "    \n",
    "    # Calculate precision and recall continuously along the tree_score values\n",
    "    d=d[[classify_col,'tree_score','filter']].sort_values(by=['tree_score'])\n",
    "    \n",
    "    d['label'] = np.where(d[classify_col]=='fp',0,1)\n",
    "\n",
    "    d.loc[d[classify_col]=='fn','filter']='MISS'\n",
    "\n",
    "    num=len(d)\n",
    "    numPos=sum(d['label'])\n",
    "    numNeg=num-numPos\n",
    "    if num<10:\n",
    "        return (pd.DataFrame(),None,numPos,numNeg)\n",
    "    \n",
    "    d['fn']=np.cumsum(d['label'])\n",
    "    d['tp']=numPos-(d['fn'])\n",
    "    d['fp']=numNeg-np.cumsum(1-d['label'])\n",
    "\n",
    "    d['recall']=d['tp']/(d['tp']+d['fn'])\n",
    "    d['precision']=d['tp']/(d['tp']+d['fp'])\n",
    "\n",
    "    d['f1']=d['tp']/(d['tp']+0.5*d['fn']+0.5*d['fp'])\n",
    "\n",
    "    d['mask']=((d['tp']+d['fn'])>=20) & ((d['tp']+d['fp'])>=20) & (d['tree_score']>=0)\n",
    "    if len(d[d['mask']])==0:\n",
    "        return (pd.DataFrame(),None,numPos,numNeg)\n",
    "\n",
    "    # Calculate the precision and recall as ouputted by the model (based on the FILTER column)\n",
    "    d['class'] = np.where(d['label']==0,'FP','FN')\n",
    "    d.loc[(d['label']==1) & (d['filter']=='PASS'),'class']='TP'\n",
    "    d.loc[(d['label']==0) & (d['filter']!='PASS'),'class']='TN'\n",
    "\n",
    "    fn=len(d[d['class']=='FN'])\n",
    "    tp=len(d[d['class']=='TP'])\n",
    "    fp=len(d[d['class']=='FP'])\n",
    "\n",
    "    recall=tp/(tp+fn) if (tp+fn>0) else np.nan\n",
    "    precision=tp/(tp+fp) if (tp+fp>0) else np.nan\n",
    "    max_recall=1-len(d[d['filter']=='MISS'])/numPos\n",
    "\n",
    "    f1=tp/(tp+0.5*fn+0.5*fp)\n",
    "    \n",
    "    return (d[['recall','precision']][d['mask']],\n",
    "            dict({'recall':recall,'precision':precision,'f1':f1}),\n",
    "            numPos,numNeg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPerformance(perfCurve,optRes,categories,source=sources,ext=None,img=None,legend=None,optRes_SEC=None):\n",
    "    n=len(categories)\n",
    "    nrow=int(np.ceil(n/5))\n",
    "    ncol=int(max(5,n))\n",
    "    fig, ax = plt.subplots(1,n,figsize=(4*n,4))\n",
    "    #fig, ax = plt.subplots(1,ncol) #figsize=(4*nrow,4*ncol)\n",
    "    #ax=ax.flatten()\n",
    "    \n",
    "    col=['r','b','g','m','k']\n",
    "\n",
    "    for i,cat in enumerate(categories):\n",
    "        for j,s in enumerate(source):\n",
    "            perf=perfCurve[s][cat]\n",
    "            opt=optRes[s][cat]\n",
    "            if optRes_SEC is not None:\n",
    "                opt_sec=optRes_SEC[s][cat]\n",
    "            if not perf.empty:\n",
    "                ax[i].plot(perf.recall,perf.precision,'-',label=s,color=col[j])    \n",
    "                ax[i].plot(opt.get('recall'),opt.get('precision'),'o',color=col[j])\n",
    "                if optRes_SEC is not None:\n",
    "                    ax[i].plot(opt_sec.get('recall'),opt_sec.get('precision'),'o',color=\"black\")\n",
    "            title=cat if ext==None else '{0} ({1})'.format(cat,ext)\n",
    "            ax[i].set_title(title)\n",
    "            ax[i].set_xlabel(\"Recall\")\n",
    "            ax[i].set_xlim([0.4,1])\n",
    "            ax[i].set_ylim([0.4,1])\n",
    "            ax[i].grid(True)\n",
    "\n",
    "    ax[0].set_ylabel(\"Precision\")\n",
    "    if legend: \n",
    "        ax[0].legend(loc='lower left')    \n",
    "    if img:\n",
    "        nxp.save(fig,imgpref+img,'png',outdir=imgdir)\n",
    "    \n",
    "    \n",
    "def getPerformance(data, categories, sources):\n",
    "    optTab={}\n",
    "    optRes={}\n",
    "    perfCurve={}\n",
    "    for s in sources:\n",
    "        optTab[s]=pd.DataFrame()\n",
    "        optRes[s]={}\n",
    "        perfCurve[s]={}\n",
    "\n",
    "        for i,cat in enumerate(categories):\n",
    "            d=filterByCategory(data[s],cat)\n",
    "            perf,opt,pos,neg=calcPerformance(d)\n",
    "            perfCurve[s][cat]=perf\n",
    "            optRes[s][cat]=opt\n",
    "            \n",
    "            row=pd.DataFrame({'# pos':pos,\n",
    "                              '# neg':neg,\n",
    "                              'max recall':np.nan if perf.empty else max(perf.recall),\n",
    "                              'recall':np.nan if perf.empty else opt.get('recall'),\n",
    "                              'precision':np.nan if perf.empty else opt.get('precision'),\n",
    "                              'F1':np.nan if perf.empty else opt.get('f1')\n",
    "                             },index=[cat])\n",
    "            optTab[s]=pd.concat([optTab[s],row])\n",
    "            \n",
    "    return optTab,optRes,perfCurve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Performance over all Data\n",
    "The concordance between the variant calling results and the ground truth sample is presented below.\n",
    "* Red line - precision and recall over different tree-scores.\n",
    "* Red dot - precision and recall values for the chosen threshold.\n",
    "* Black dot -precision and recall after filtering systematic errors (SEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_sec(x):\n",
    "    res = False\n",
    "    if x is not None:\n",
    "        if x==x:\n",
    "            if \"SEC\" in x:\n",
    "                res=True\n",
    "    return res\n",
    "\n",
    "sec_df = data['whole genome'].copy()\n",
    "data_SEC={}\n",
    "if 'blacklst' in sec_df.columns:\n",
    "    is_sec = sec_df['blacklst'].apply(has_sec)\n",
    "    sec_df.loc[is_sec,'filter'] = \"SEC\"\n",
    "    sec_df.loc[(is_sec) & (sec_df['classify_gt']=='tp'),'classify_gt'] = \"fn\"\n",
    "    sec_df_new=sec_df[~((is_sec) & (sec_df['classify_gt']=='fp'))]\n",
    "    data_SEC = {'whole genome': sec_df_new, 'Trained wo gt': data['Trained wo gt'].copy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=['SNP','Indel','non-hmer Indel','non-hmer Indel w/o LCR','hmer Indel <=4','hmer Indel >4,<=8']\n",
    "optTab1,optRes,perfCurve=getPerformance(data,categories,sources)\n",
    "if data_SEC :\n",
    "    SEC_optTab1,SEC_optRes,SEC_perfCurve=getPerformance(data_SEC,categories,sources)\n",
    "    plotPerformance(perfCurve,optRes,categories,img='all.primary',source={'whole genome':sources['whole genome']},optRes_SEC=SEC_optRes)\n",
    "else:\n",
    "    plotPerformance(perfCurve,optRes,categories,img='all.primary',source={'whole genome':sources['whole genome']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=['hmer Indel 4','hmer Indel 5','hmer Indel 6','hmer Indel 7','hmer Indel 8','hmer Indel >8,<=10']\n",
    "optTab2,optRes,perfCurve=getPerformance(data,categories,sources)\n",
    "if data_SEC :\n",
    "    SEC_optTab2,SEC_optRes,SEC_perfCurve=getPerformance(data_SEC,categories,sources)\n",
    "    plotPerformance(perfCurve,optRes,categories,img='all.primary',source={'whole genome':sources['whole genome']},optRes_SEC=SEC_optRes)\n",
    "else:\n",
    "    plotPerformance(perfCurve,optRes,categories,img='all.primary',source={'whole genome':sources['whole genome']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.2%}'.format\n",
    "\n",
    "optTab={}\n",
    "for s in sources:\n",
    "    optTab[s]=pd.concat([optTab1[s], optTab2[s]])\n",
    "\n",
    "df=pd.concat([optTab[s] for s in sources], axis=1, keys=[s for s in sources])\n",
    "df[['whole genome']].to_hdf(h5outfile, key=\"all_data\")\n",
    "\n",
    "if data_SEC :\n",
    "    df_SEC=pd.concat([SEC_optTab1['whole genome'],SEC_optTab2['whole genome']])\n",
    "    df_SEC.to_hdf(h5outfile, key=\"sec_data\")\n",
    "    display(pd.concat([df['whole genome'],df_SEC], keys=['Whole genome','After filtering systematic errors'], axis=1))\n",
    "else:\n",
    "    display(df[['whole genome']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.1 Homozygous genotyping accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision and recall of called homozygous variants (where the variant was not classfied as False Negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "categories=['SNP','Indel','non-hmer Indel','non-hmer Indel w/o LCR','hmer Indel <=4','hmer Indel >4,<=8']\n",
    "\n",
    "hmzData={}\n",
    "for s in sources:\n",
    "        d=data[s]\n",
    "        hmzData[s]=d[(d['gt_ground_truth']==(1,1)) & (d['classify']!='fn')]\n",
    "optTab,optRes,perfCurve=getPerformance(hmzData,categories,sources)\n",
    "df=pd.concat([optTab[s] for s in sources], axis=1, keys=[s for s in sources])\n",
    "df[['whole genome']].to_hdf(h5outfile, key=\"all_data_homozygous\")\n",
    "\n",
    "display(df[['whole genome']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.2 Stratified by base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (A,T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "categories=['SNP','Indel','hmer Indel <=4','hmer Indel >4,<=8','hmer Indel >8,<=10','hmer Indel 8']\n",
    "\n",
    "baseData={}\n",
    "b =('A','T')\n",
    "for s in sources:\n",
    "        d=data[s]\n",
    "        baseData[s]=d[((d['indel']==False) & ((d['ref']==b[0]) | (d['ref']==b[1]))) |\n",
    "                      ((d['hmer_indel_length']>0) & ((d['hmer_indel_nuc']==b[0]) | (d['hmer_indel_nuc']==b[1])))\n",
    "                     ]\n",
    "optTab1,optRes,perfCurve=getPerformance(baseData,categories,sources)\n",
    "for s in sources:\n",
    "    optTab1[s].rename(index={a:'{0} ({1}/{2})'.format(a,b[0],b[1]) for a in optTab1[s].index}, inplace=True)\n",
    "plotPerformance(perfCurve,optRes,categories,source={'whole genome':sources['whole genome']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### (G,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "categories=['SNP','Indel','hmer Indel <=4','hmer Indel >4,<=8','hmer Indel >8,<=10','hmer Indel 6']\n",
    "baseData={}\n",
    "b =('C','G')\n",
    "for s in sources:\n",
    "        d=data[s]\n",
    "        baseData[s]=d[((d['indel']==False) & ((d['ref']==b[0]) | (d['ref']==b[1]))) |\n",
    "                      ((d['hmer_indel_length']>0) & ((d['hmer_indel_nuc']==b[0]) | (d['hmer_indel_nuc']==b[1])))\n",
    "                     ]\n",
    "optTab2,optRes,perfCurve=getPerformance(baseData,categories,sources)\n",
    "for s in sources:\n",
    "    optTab2[s].rename(index={a:'{0} ({1}/{2})'.format(a,b[0],b[1]) for a in optTab2[s].index}, inplace=True)\n",
    "plotPerformance(perfCurve,optRes,categories,source={'whole genome':sources['whole genome']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optTab={}\n",
    "for s in sources:\n",
    "    optTab[s]=pd.concat([optTab1[s], optTab2[s]])\n",
    "df=pd.concat([optTab[s] for s in sources], axis=1, keys=[s for s in sources])\n",
    "df[['whole genome']].to_hdf(h5outfile, key=\"all_data_per_base\")\n",
    "display(df[['whole genome']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Performance over UG high confidence regions\n",
    "\n",
    "Variant calling peformance exclusing genomic areas where UG performance is poor, i.e:\n",
    "- Homopolymers - runs of length 11 bp and above, padded with four bases around the genomic coordinates,\n",
    "- AT-rich regions - bases where the GC content of the surrounding 40 bases is lower than 5%,\n",
    "- Tandem repeats,\n",
    "- Low mapping quality - regions that are covered by at least 20 reads, but less than 10% of these reads are aligned with mapping quality > 20,\n",
    "- High coverage variability - regions with coverage that is highly variable between samples (std/mean > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filtData={}\n",
    "for s in sources:\n",
    "    d=data[s]\n",
    "    if s == 'whole genome':\n",
    "        filtData[s]=d.query(\"ug_hcr==True\").copy()\n",
    "    else:\n",
    "        filtData[s]=d.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def has_sec(x):\n",
    "    res = False\n",
    "    if x is not None:\n",
    "        if x==x:\n",
    "            if \"SEC\" in x:\n",
    "                res=True\n",
    "    return res\n",
    "\n",
    "sec_df = filtData['whole genome'].copy()\n",
    "data_SEC={}\n",
    "if 'blacklst' in sec_df.columns:\n",
    "    is_sec = sec_df['blacklst'].apply(has_sec)\n",
    "    sec_df.loc[is_sec,'filter'] = \"SEC\"\n",
    "    sec_df.loc[(is_sec) & (sec_df['classify_gt']=='tp'),'classify_gt'] = \"fn\"\n",
    "    sec_df_new=sec_df[~((is_sec) & (sec_df['classify_gt']=='fp'))]\n",
    "    data_SEC = {'whole genome': sec_df_new, 'Trained wo gt': filtData['Trained wo gt'].copy()}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "categories=['SNP','Indel','non-hmer Indel','non-hmer Indel w/o LCR','hmer Indel <=4','hmer Indel >4,<=8']\n",
    "optTab1,optRes,perfCurve=getPerformance(filtData,categories,sources)\n",
    "if data_SEC :\n",
    "    SEC_optTab1,SEC_optRes,SEC_perfCurve=getPerformance(data_SEC,categories,sources)\n",
    "    plotPerformance(perfCurve,optRes,categories,img='all.primary',source={'whole genome':sources['whole genome']},optRes_SEC=SEC_optRes)\n",
    "else:\n",
    "    plotPerformance(perfCurve,optRes,categories,img='all.primary',source={'whole genome':sources['whole genome']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "categories=['hmer Indel 4','hmer Indel 5','hmer Indel 6','hmer Indel 7','hmer Indel 8','hmer Indel >8,<=10']\n",
    "optTab2,optRes,perfCurve=getPerformance(filtData,categories,sources)\n",
    "if data_SEC :\n",
    "    SEC_optTab2,SEC_optRes,SEC_perfCurve=getPerformance(data_SEC,categories,sources)\n",
    "    plotPerformance(perfCurve,optRes,categories,img='all.primary',source={'whole genome':sources['whole genome']},optRes_SEC=SEC_optRes)\n",
    "else:\n",
    "    plotPerformance(perfCurve,optRes,categories,img='all.primary',source={'whole genome':sources['whole genome']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.2%}'.format\n",
    "\n",
    "optTab={}\n",
    "for s in sources:\n",
    "    optTab[s]=pd.concat([optTab1[s], optTab2[s]])\n",
    "\n",
    "df=pd.concat([optTab[s] for s in sources], axis=1, keys=[s for s in sources])\n",
    "df[['whole genome']].to_hdf(h5outfile, key=\"ug_hcr\")\n",
    "\n",
    "if data_SEC :\n",
    "    df_SEC=pd.concat([SEC_optTab1['whole genome'],SEC_optTab2['whole genome']])\n",
    "    df_SEC.to_hdf(h5outfile, key=\"ug_hcr_sec_data\")\n",
    "    display(pd.concat([df['whole genome'],df_SEC], keys=['Whole genome','After filtering systematic errors'], axis=1))\n",
    "else:\n",
    "    display(df[['whole genome']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.1 Homozygous genotyping accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "categories=['SNP','Indel','non-hmer Indel','hmer Indel <=4','hmer Indel >4,<=8','hmer Indel >8,<=10']\n",
    "\n",
    "hmzData={}\n",
    "for s in sources:\n",
    "        d=filtData[s]\n",
    "        hmzData[s]=d[(d['gt_ground_truth']==(1,1)) & (d['classify']!='fn')]\n",
    "optTab,optRes,perfCurve=getPerformance(hmzData,categories,sources)\n",
    "df=pd.concat([optTab[s] for s in sources], axis=1, keys=[s for s in sources])\n",
    "df[['whole genome']].to_hdf(h5outfile, key=\"ug_hcr_homozygous\")\n",
    "display(df[['whole genome']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Performance over regions with coverage>=20 and excluding areas with mappability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if 'well_mapped_coverage' in data['whole genome'].columns:\n",
    "    filtData={}\n",
    "    for s in sources:\n",
    "        d=data[s]\n",
    "        filtData[s]=d[(d['well_mapped_coverage']>=20) &\n",
    "                      (d['mappability.0'])\n",
    "                     ]\n",
    "\n",
    "    categories=['SNP','Indel','non-hmer Indel','non-hmer Indel w/o LCR','hmer Indel <=4','hmer Indel >4,<=8']\n",
    "    optTab1,optRes,perfCurve=getPerformance(filtData,categories,sources)\n",
    "    plotPerformance(perfCurve,optRes,categories,img='hicvg.primary',source={'whole genome':sources['whole genome']})\n",
    "\n",
    "    categories=['hmer Indel 4','hmer Indel 5','hmer Indel 6','hmer Indel 7','hmer Indel 8','hmer Indel >8,<=10']\n",
    "    optTab2,optRes,perfCurve=getPerformance(filtData,categories,sources)\n",
    "    plotPerformance(perfCurve,optRes,categories,img='hicvg.hmers',source={'whole genome':sources['whole genome']})\n",
    "\n",
    "    optTab={}\n",
    "    for s in sources:\n",
    "        optTab[s]=pd.concat([optTab1[s], optTab2[s]])\n",
    "    df=pd.concat([optTab[s] for s in sources], axis=1, keys=[s for s in sources])\n",
    "    df[['whole genome']].to_hdf(h5outfile, key=\"good_cvg_data\")\n",
    "    # defTable=df.copy()\n",
    "    display(df[['whole genome']])\n",
    "else:\n",
    "    print(\"No coverage data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Homozygous genotyping accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "categories=['SNP','Indel','non-hmer Indel','non-hmer Indel w/o LCR','hmer Indel <=4','hmer Indel >4,<=8']\n",
    "\n",
    "hmzData={}\n",
    "for s in sources:\n",
    "        d=filtData[s]\n",
    "        hmzData[s]=d[(d['gt_ground_truth']==(1,1)) & (d['classify_gt']!='fn')]\n",
    "optTab,optRes,perfCurve=getPerformance(hmzData,categories,sources)\n",
    "df=pd.concat([optTab[s] for s in sources], axis=1, keys=[s for s in sources])\n",
    "df[['whole genome']].to_hdf(h5outfile, key=\"good_cvg_data_homozygous\")\n",
    "display(df[['whole genome']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A block comparing model with and without ground truth . Only shown if h5_model_file is provided in the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_w_gt = parser.get('VarReport', 'h5_model_file', fallback=None)    \n",
    "\n",
    "if (trained_w_gt is not None):\n",
    "    display(Markdown(\"\"\"\n",
    "##  5. Trained with and without Ground Truth\n",
    "<ul>\n",
    "<li><b>Trained wo gt - Trained without ground truth </b></li>\n",
    "Random forest model trained on chromosome 9 using known variants in dbSNP and on common fp variants\n",
    "<li><b>Trained with gt - Trained with ground truth</b></li>\n",
    "Simple threshold model trained on chromosome 9 using its own ground truth\n",
    "</ul>\n",
    "\"\"\") )\n",
    "    sources['Trained with gt'] = (trained_w_gt, \"scored_concordance\")\n",
    "    data['Trained with gt']    = pd.read_hdf(trained_w_gt, \"scored_concordance\", mode='r')\n",
    "    data['Trained with gt']= data['Trained with gt'].rename(columns=rename_dict)\n",
    "\n",
    "    categories=['SNP','Indel','non-hmer Indel','non-hmer Indel w/o LCR','hmer Indel <=4','hmer Indel >4,<=8']\n",
    "    optTab1,optRes,perfCurve=getPerformance(data,categories,sources)\n",
    "    plotPerformance(perfCurve,optRes,categories,img='all.primary',source={'Trained wo gt':sources['Trained wo gt'], 'Trained with gt': sources['Trained with gt']},legend=True)\n",
    "    \n",
    "    categories=['hmer Indel 4','hmer Indel 5','hmer Indel 6','hmer Indel 7','hmer Indel 8','hmer Indel >8,<=10']\n",
    "    optTab2,optRes,perfCurve=getPerformance(data,categories,sources)\n",
    "    plotPerformance(perfCurve,optRes,categories,img='all.hmers',source={'Trained wo gt':sources['Trained wo gt'], 'Trained with gt': sources['Trained with gt']},legend=True)\n",
    "    \n",
    "    pd.options.display.float_format = '{:,.2%}'.format\n",
    "    sources={'Trained wo gt':sources['Trained wo gt'], 'Trained with gt': sources['Trained with gt']}\n",
    "    optTab={}\n",
    "    for s in ['Trained wo gt', 'Trained with gt']:\n",
    "        optTab[s]=pd.concat([optTab1[s], optTab2[s]])\n",
    "    df=pd.concat([optTab[s] for s in sources], axis=1, keys=[s for s in sources])\n",
    "    df.to_hdf(h5outfile, key=\"trained_w_wo_gt\")\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ('well_mapped_coverage' in data['whole genome'].columns) and (trained_w_gt is not None):\n",
    "    filtData={}\n",
    "    d = data['Trained with gt']\n",
    "    filtData['Trained with gt'] = d[(d['well_mapped_coverage']>=20) &\n",
    "                                    (d['mappability.0']) ]\n",
    "\n",
    "    categories=['SNP','Indel','non-hmer Indel','non-hmer Indel w/o LCR','hmer Indel <=4','hmer Indel >4,<=8',\n",
    "               'hmer Indel 4','hmer Indel 5','hmer Indel 6','hmer Indel 7','hmer Indel 8','hmer Indel >8,<=10']\n",
    "    optTab,optRes,perfCurve = getPerformance(filtData,categories,{'Trained with gt': sources['Trained with gt']})\n",
    "\n",
    "    %matplotlib agg\n",
    "    d=optTab['Trained with gt'][['max recall','recall','precision']]\n",
    "    labels=['SNP','Indel','nhmer','nhmer w/o LCR','hmer 2-4','hmer 5-8','hmer 4','hmer 5','hmer 6','hmer 7','hmer 8','hmer 9-10']\n",
    "    fig=plt.figure()\n",
    "    ax=d.plot()\n",
    "    plt.xticks(np.arange(len(d.index)), rotation=30, ha='right')\n",
    "    ax.set_xticklabels(labels)\n",
    "    plt.ylim([0.4,1.05])\n",
    "    plt.grid()\n",
    "    plt.title('Cvg>20X, Trained variant calls')\n",
    "    plt.tight_layout()\n",
    "    nxp.save(fig,imgpref+'summary','png',outdir=imgdir)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}