{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bddb36",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "usage = \"\"\"Run with papermill:\n",
    "     \n",
    "papermill srsnv_report.ipynb output_srsnv_report.ipynb \\\n",
    "    -p report_name <> \\\n",
    "    -p model_file <> \\\n",
    "    -p params_file <> \\\n",
    "    -p qc_h5_file <> \\\n",
    "    -p output_roc_plot <> \\\n",
    "    -p output_LoD_plot <> \\\n",
    "    -p qual_vs_ppmseq_tags_table <> \\\n",
    "    -p output_LoD_qual_plot <> \\\n",
    "    -p output_cm_plot <> \\\n",
    "    -p output_obsereved_qual_plot <> \\\n",
    "    -p output_ML_qual_hist <> \\\n",
    "    -p output_qual_per_feature <> \\\n",
    "    -p output_bepcr_hists <> \\\n",
    "    -p output_bepcr_fpr <> \\\n",
    "    -p output_bepcr_recalls <>\n",
    "Then convert to html\n",
    "\n",
    "jupyter nbconvert --to html output_srsnv_report.ipynb --no-input --output srsnv_report.html\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df91b0b8-6bdf-4a98-8bd7-b94bdac764b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import base64\n",
    "from IPython.display import Image, HTML, display\n",
    "import joblib\n",
    "import json\n",
    "import math\n",
    "\n",
    "pd.options.display.max_rows = 200\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc8efe7-340b-4a6e-acf4-bb3bc8415f53",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# papermill parameters\n",
    "report_name = None\n",
    "model_file = None\n",
    "params_file = None\n",
    "srsnv_qc_h5_file = None\n",
    "output_roc_plot = None\n",
    "output_LoD_plot = None\n",
    "qual_vs_ppmseq_tags_table = None\n",
    "training_progerss_plot = None\n",
    "SHAP_importance_plot = None\n",
    "SHAP_beeswarm_plot = None\n",
    "trinuc_stats_plot = None\n",
    "output_LoD_qual_plot = None\n",
    "output_cm_plot = None\n",
    "output_obsereved_qual_plot = None\n",
    "output_ML_qual_hist = None\n",
    "output_qual_per_feature = None\n",
    "output_bepcr_hists = None\n",
    "output_bepcr_fpr = None\n",
    "output_bepcr_recalls = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027c197c-26c4-4e90-be14-4ac2c13d07bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check that we got all the inputs\n",
    "missing = list()\n",
    "for varname in [\n",
    "    \"report_name\",\n",
    "    \"model_file\",\n",
    "    \"params_file\",\n",
    "    \"srsnv_qc_h5_file\", \n",
    "    \"output_roc_plot\",\n",
    "    \"output_LoD_plot\",\n",
    "    \"qual_vs_ppmseq_tags_table\",\n",
    "    \"training_progerss_plot\",\n",
    "    \"SHAP_importance_plot\", \n",
    "    \"SHAP_beeswarm_plot\",\n",
    "    \"trinuc_stats_plot\", \n",
    "    \"output_LoD_qual_plot\",\n",
    "    \"output_cm_plot\",\n",
    "    \"output_obsereved_qual_plot\",\n",
    "    \"output_ML_qual_hist\",\n",
    "    \"output_qual_per_feature\",\n",
    "    \"output_bepcr_hists\",\n",
    "    \"output_bepcr_fpr\",\n",
    "    \"output_bepcr_recalls\",\n",
    "]:\n",
    "    if locals()[varname] is None:\n",
    "        missing.append(varname)\n",
    "\n",
    "if len(missing) > 0:\n",
    "    raise ValueError(f\"Following inputs missing:\\n{(os.linesep).join(missing)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8a050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load files\n",
    "model = joblib.load(model_file)\n",
    "if isinstance(model, dict): # joblib after BIOIN-1558\n",
    "    model = model['models']\n",
    "if isinstance(model, list): # For models saved from CV\n",
    "    model = model[0]\n",
    "with open(params_file, 'r', encoding=\"utf-8\") as f:\n",
    "    params = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e544b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_test_train(image_path,titlestr, report_name='test'):\n",
    "    # other_dataset = 'train' if report_name == 'test' else 'test'\n",
    "    other_dataset = 'test'\n",
    "    image_path1 = image_path+'.png'\n",
    "    image_path2 = image_path.replace(f\".{report_name}.\",f\".{other_dataset}.\")+'.png'\n",
    "\n",
    "    img1 = mpimg.imread(image_path1)\n",
    "    img2 = mpimg.imread(image_path2)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 10),constrained_layout=True)\n",
    "    ax[0].imshow(img1)\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title(report_name,fontsize=20)\n",
    "    ax[1].imshow(img2)\n",
    "    ax[1].axis('off')\n",
    "    ax[1].set_title(other_dataset,fontsize=20)\n",
    "    \n",
    "    fig.suptitle(titlestr,fontsize=24,y=0.95)\n",
    "    plt.show()\n",
    "\n",
    "dataname = params_file.split('/')[-1].split('.')[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67210add",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_with_vertical_lines(df, sep_columns=None, unique_id='dataframe'):\n",
    "    \"\"\"\n",
    "    Displays a DataFrame in a Jupyter notebook with vertical lines between selected columns.\n",
    "    Applies styling only to the specified DataFrame using a unique ID.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to display.\n",
    "    sep_columns (list of int): The list of column indices where vertical lines should be drawn. \n",
    "                               The line is drawn before these column indices.\n",
    "    unique_id (str): A unique ID for the DataFrame to scope the CSS styling.\n",
    "    \"\"\"\n",
    "    # Convert DataFrame to HTML with a unique ID and include index\n",
    "    html = df.to_html(border=0, classes='dataframe', justify='left', index=True)\n",
    "    html = html.replace('<table', f'<table id=\"{unique_id}\"')\n",
    "\n",
    "    # Add styles for vertical lines with unique ID\n",
    "    style = f'''\n",
    "    <style>\n",
    "    #{unique_id} th {{\n",
    "        text-align: left;  /* Left-align column headers */\n",
    "        padding: 6px;  /* Adjust padding if necessary */\n",
    "    }}\n",
    "    #{unique_id} td {{\n",
    "        text-align: right;  /* Right-align table body cells */\n",
    "        padding: 6px;  /* Adjust padding if necessary */\n",
    "    }}\n",
    "    #{unique_id} td, #{unique_id} th {{\n",
    "        border-right: 1px solid #000;\n",
    "    }}\n",
    "    '''\n",
    "    \n",
    "    # If specific columns are selected for separation lines\n",
    "    if sep_columns is not None:\n",
    "        sep_style = \"\"\n",
    "        for col in sep_columns:\n",
    "            sep_style += f\"#{unique_id} td:nth-child({col + 1}), #{unique_id} th:nth-child({col + 1}) {{ border-right: 2px solid black !important; }}\\n\"\n",
    "        style += sep_style\n",
    "    \n",
    "    # Close style tags\n",
    "    style += \"</style>\"\n",
    "    \n",
    "    # Display the styled HTML\n",
    "    display(HTML(style + html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae775ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_with_max_width(image_path, w=1.0):\n",
    "    \"\"\"\n",
    "    Displays an image in a Jupyter notebook with a width that is a fraction of the notebook frame.\n",
    "\n",
    "    Parameters:\n",
    "    - image_path: Path to the image file.\n",
    "    - w: Fraction of the notebook frame width (between 0 and 1).\n",
    "    \"\"\"\n",
    "    # Convert w to percentage for use in HTML/CSS\n",
    "    width_percent = int(w * 100)\n",
    "\n",
    "    # Read the image file and encode it in base64\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        encoded_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    \n",
    "    # Create an HTML string to display the image with the desired max-width\n",
    "    image_html = f'<img src=\"data:image/png;base64,{encoded_image}\" style=\"max-width: {width_percent}%; height: auto;\">'\n",
    "    \n",
    "    # Display the image using HTML\n",
    "    display(HTML(image_html))\n",
    "\n",
    "def display_images_grid(image_paths, w=1/3):\n",
    "    \"\"\"\n",
    "    Displays multiple images in a grid layout in a Jupyter notebook.\n",
    "    Images are displayed in rows, with each image's width being a fraction of the notebook frame.\n",
    "\n",
    "    Parameters:\n",
    "    - image_paths: List of paths to the image files.\n",
    "    - w: Fraction of the notebook frame width for each image (between 0 and 1).\n",
    "    \"\"\"\n",
    "    # Convert w to percentage for use in HTML/CSS\n",
    "    width_percent = int(w * 100)\n",
    "    \n",
    "    # Calculate the number of images per row\n",
    "    images_per_row = math.floor(1 / w)\n",
    "    \n",
    "    # Start the HTML string for the grid\n",
    "    images_html = ''\n",
    "    \n",
    "    # Loop through the images and create rows\n",
    "    for i in range(0, len(image_paths), images_per_row):\n",
    "        # Start a new row\n",
    "        images_html += '<div style=\"display: flex; justify-content: space-between;\">'\n",
    "        \n",
    "        # Add each image in the row\n",
    "        for image_path in image_paths[i:i + images_per_row]:\n",
    "            # Read the image file and encode it in base64\n",
    "            with open(image_path, \"rb\") as image_file:\n",
    "                encoded_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "            \n",
    "            # Add the image HTML to the row, with max-width and height auto\n",
    "            images_html += f'<img src=\"data:image/png;base64,{encoded_image}\" style=\"max-width: {width_percent}%; height: auto;\">'\n",
    "        \n",
    "        # Close the div for the row\n",
    "        images_html += '</div>'\n",
    "    \n",
    "    # Display the images in a grid using HTML\n",
    "    display(HTML(images_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a5d78f-47c4-4bec-b008-0b032b2db039",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(HTML(f'<font size=\"6\">SRSNV pipeline report </font>'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd7365f9-f154-415b-9775-2a95d9bc6696",
   "metadata": {},
   "source": [
    "* This report contains an analysis of the SRSNV model training.\n",
    "* We train as binary classifier per read. \n",
    "* The probabilities are translated to quality: quality = -10*log10(probability). \n",
    "* The quality is used as a threshold for discriminating true and false variants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb012b45",
   "metadata": {},
   "source": [
    "<!--TOC_PLACEHOLDER-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e25e50b",
   "metadata": {},
   "source": [
    "# Run details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732ed3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_info_table = pd.read_hdf(srsnv_qc_h5_file, key='run_info_table')\n",
    "run_info_table.to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464a59cd",
   "metadata": {},
   "source": [
    "# General statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb191aa3",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae879a3",
   "metadata": {},
   "source": [
    "## Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9effb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_quality_table = pd.read_hdf(srsnv_qc_h5_file, key='run_quality_table_display')\n",
    "display_with_vertical_lines(run_quality_table, unique_id='run_quality_table')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791c15fe",
   "metadata": {},
   "source": [
    "## SNVQ vs Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f6269c",
   "metadata": {},
   "source": [
    "We calculate the residual SNV rate as following: \n",
    "```\n",
    "error rate in test data = # errors / # bases sequenced\n",
    "```\n",
    "where:\n",
    "```\n",
    "# errors = # of single substitution snps > filter thresh\n",
    "# bases sequenced = # of bases aligned * % mapq60 * ratio_of_bases_in_coverage_range *\n",
    "                    read_filter_correction_factor * recall[threshold]\n",
    "```\n",
    "and: \n",
    "```\n",
    "# of bases aligned = mean_coverage * bases in region * downsampling factor\n",
    "downsampling factor = % of the featuremap reads sampled for test set\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4575fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path1 = output_LoD_plot+'.png'\n",
    "display(HTML(f'<font size=\"6\">Test LoD simulation </font>'))\n",
    "display_image_with_max_width(image_path1, 0.7)\n",
    "# display(Image(filename=image_path1), width=800, height=800)\n",
    "# other_dataset = 'train' if report_name=='test' else 'test'\n",
    "# other_dataset = 'test'\n",
    "# image_path2 = output_LoD_plot.replace(f\".{report_name}.\",f\".{other_dataset}.\")+'.png'\n",
    "# display(HTML(f'<font size=\"6\">Train LoD simulation </font>'))\n",
    "# display(Image(filename=image_path2, width=800, height=800))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281bc78a",
   "metadata": {},
   "source": [
    "# SNVQ and statistics of features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b5201e",
   "metadata": {},
   "source": [
    "## Categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457f1a9b",
   "metadata": {},
   "source": [
    "### SNVQ vs start/end ppmSeq tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75af1951",
   "metadata": {},
   "source": [
    "The table below present median SNVQ values on the TP (homozygous substitutions) training dataset. Numbers in square brackets are the proportion of datapoints with each start/end tag combination. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fccffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_with_max_width(qual_vs_ppmseq_tags_table+'.png', 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9645c339",
   "metadata": {},
   "source": [
    "### Quality as function of trinuc context and alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fb35c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_with_max_width(trinuc_stats_plot+'.png', 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc20873",
   "metadata": {},
   "source": [
    "## Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2db658",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = [output_qual_per_feature + f + '.png' for f in params[\"numerical_features\"]]\n",
    "display_images_grid(image_paths, w=1/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bccb99",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040677d8",
   "metadata": {},
   "source": [
    "## Training progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5965a238",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_with_max_width(training_progerss_plot+'.png', 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b92541",
   "metadata": {},
   "source": [
    "# Feature importance: SHAP\n",
    "SHAP values are an estimation of how much each feature value has contributed to the model prediction, in our binary classification case, to the model's logit value. The output logit equals an overall bias term plus the sum of all features SHAP values for a given input. Large positive SHAP values \"push\" the prediction towards True, and large negative values towards False. \n",
    "\n",
    "For example, for a linear classifier (logistic regression), the logit value is $$y = \\sum_i w_i x_i,$$ where the $x_i$'s are the feature values. The SHAP value of feature $i$ for this prediction is $w_i x_i$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d8cba1",
   "metadata": {},
   "source": [
    "## Shap bar plot\n",
    "The following plot measure the importance of features by mean absolute shap values per feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2d7df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_with_max_width(SHAP_importance_plot+'.png', 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bb420e",
   "metadata": {},
   "source": [
    "## SHAP beeswarm plot\n",
    "More insight into the model's prediction is available from the beeswarm plot. This is a scatter plot of SHAP values (each point is the SHAP value for one datapoint), providing insight into how SHAP values are distributed by feature. Moreover, the colors represent the feature value at the given datapoint, revealing whether particular values tend to affect the predictions in a certain direction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007a9955",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_with_max_width(SHAP_beeswarm_plot+'.png', 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6091c7",
   "metadata": {},
   "source": [
    "The number in brackets next to categorical features refers to the appropriate colormap on the right that corresponds to the possible values of the feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ac0b8d",
   "metadata": {},
   "source": [
    "---\n",
    "# Remnants from old report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e78202",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display_test_train(output_LoD_qual_plot,\"LoD vs. ML qual \\n\"+dataname, report_name=report_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7027ba75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display_test_train(output_roc_plot,\"ROC curve \\n\"+dataname, report_name=report_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd27291b",
   "metadata": {},
   "source": [
    "## Residual SNV rate vs Retention and LoD simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52811fb1",
   "metadata": {},
   "source": [
    "# Training metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52811fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# title = 'Confusion matrix'\n",
    "# display(HTML(f'<font size=\"4\">{title}</font>'))\n",
    "# display_test_train(output_cm_plot,dataname, report_name=report_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39827279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# title = 'ML qual hists by class'\n",
    "# display(HTML(f'<font size=\"4\">{title}</font>'))\n",
    "# display_test_train(output_ML_qual_hist,dataname, report_name=report_name)\n",
    "\n",
    "# display(HTML(f'<font size=\"4\">Stratified by category </font>'))\n",
    "# subset_data_list = [\n",
    "#     'mixed_cycle_skip',\n",
    "#     'mixed_non_cycle_skip',\n",
    "#     'non_mixed_cycle_skip',\n",
    "#     'non_mixed_non_cycle_skip',\n",
    "#     'cycle_skip',\n",
    "#     'non_cycle_skip',\n",
    "# ]\n",
    "\n",
    "# for suffix in subset_data_list:\n",
    "#     image_path = output_bepcr_hists + suffix    \n",
    "#     if os.path.isfile(image_path+'.png'):\n",
    "#         display_test_train(image_path,dataname, report_name=report_name)\n",
    "\n",
    "display(HTML(f'<font size=\"4\">ML qual calibration by category </font>'))\n",
    "display_test_train(output_bepcr_fpr,dataname, report_name=report_name)\n",
    "\n",
    "# display(HTML(f'<font size=\"4\">Recall rate by category </font>'))\n",
    "# display_test_train(output_bepcr_recalls,dataname, report_name=report_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd0cff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(HTML(f'<font size=\"4\">Feature distribution per label</font>'))\n",
    "# for f in model.feature_names_in_:\n",
    "#     image_path = output_qual_per_feature + f\n",
    "#     if os.path.isfile(image_path + '.png'):        \n",
    "#         display_test_train(image_path,dataname, report_name=report_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c70897",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(HTML(f'<font size=\"4\">Input parameters: </font>'))\n",
    "\n",
    "for item in params['model_parameters']:\n",
    "    print(f\"    * {item}: {params['model_parameters'][item]}\")\n",
    "\n",
    "params_for_print = [\n",
    "    'numerical_features',\n",
    "    'categorical_features_dict',\n",
    "    'train_set_size',   \n",
    "    'test_set_size',    \n",
    "]\n",
    "for p in params_for_print:    \n",
    "    if (type(params[p]) == list):\n",
    "        print(f\"    * {p}:\")\n",
    "        for pp in params[p]:\n",
    "            print(f\"        - {pp}\")\n",
    "    elif (type(params[p]) == dict):\n",
    "        print(f\"    * {p}:\")\n",
    "        for k, v in params[p].items():\n",
    "            print(f\"        - {k}: {v}\")\n",
    "    else:\n",
    "        print(f\"    * {p}: {params[p]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genomics.py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
