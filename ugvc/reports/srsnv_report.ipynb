{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bddb36",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "usage = \"\"\"Run with papermill:\n",
    "     \n",
    "papermill srsnv_report.ipynb output_srsnv_report.ipynb \\\n",
    "    -p model_file <> \\\n",
    "    -p params_file <> \\\n",
    "    -p srsnv_qc_h5_file <> \\\n",
    "    -p output_LoD_plot <> \\\n",
    "    -p qual_vs_ppmseq_tags_table <> \\\n",
    "    -p training_progerss_plot <> \\\n",
    "    -p SHAP_importance_plot <> \\\n",
    "    -p SHAP_beeswarm_plot <> \\\n",
    "    -p trinuc_stats_plot <> \\\n",
    "    -p output_qual_per_feature <> \\\n",
    "    -p qual_histogram <> \\\n",
    "    -p logit_histogram <> \\\n",
    "    -p calibration_fn_with_hist <> \\\n",
    "Then convert to html\n",
    "\n",
    "jupyter nbconvert --to html output_srsnv_report.ipynb --no-input --output srsnv_report.html\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df91b0b8-6bdf-4a98-8bd7-b94bdac764b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import pandas as pd\n",
    "import os\n",
    "import base64\n",
    "from IPython.display import Image, HTML, display\n",
    "import joblib\n",
    "import json\n",
    "import math\n",
    "\n",
    "pd.options.display.max_rows = 200\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from ugvc.mrd.srsnv_plotting_utils import signif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc8efe7-340b-4a6e-acf4-bb3bc8415f53",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# papermill parameters\n",
    "model_file = None\n",
    "params_file = None\n",
    "srsnv_qc_h5_file = None\n",
    "output_LoD_plot = None\n",
    "qual_vs_ppmseq_tags_table = None\n",
    "training_progerss_plot = None\n",
    "SHAP_importance_plot = None\n",
    "SHAP_beeswarm_plot = None\n",
    "trinuc_stats_plot = None\n",
    "output_qual_per_feature = None\n",
    "qual_histogram = None\n",
    "logit_histogram = None\n",
    "calibration_fn_with_hist = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027c197c-26c4-4e90-be14-4ac2c13d07bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check that we got all the inputs\n",
    "missing = list()\n",
    "for varname in [\n",
    "    \"model_file\",\n",
    "    \"params_file\",\n",
    "    \"srsnv_qc_h5_file\", \n",
    "    \"output_LoD_plot\",\n",
    "    \"qual_vs_ppmseq_tags_table\",\n",
    "    \"training_progerss_plot\",\n",
    "    \"SHAP_importance_plot\", \n",
    "    \"SHAP_beeswarm_plot\",\n",
    "    \"trinuc_stats_plot\", \n",
    "    \"output_qual_per_feature\",\n",
    "    \"qual_histogram\",\n",
    "    \"logit_histogram\",\n",
    "    \"calibration_fn_with_hist\",\n",
    "]:\n",
    "    if locals()[varname] is None:\n",
    "        missing.append(varname)\n",
    "\n",
    "if len(missing) > 0:\n",
    "    raise ValueError(f\"Following inputs missing:\\n{(os.linesep).join(missing)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30c0972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_run(method):\n",
    "    @functools.wraps(method)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            return method(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in {method.__name__}: {e}\")\n",
    "            return None\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8a050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load files\n",
    "model = joblib.load(model_file)\n",
    "if isinstance(model, dict): # joblib after BIOIN-1558\n",
    "    model = model['models']\n",
    "if isinstance(model, list): # For models saved from CV\n",
    "    model = model[0]\n",
    "with open(params_file, 'r', encoding=\"utf-8\") as f:\n",
    "    params = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e544b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "@safe_run\n",
    "def display_test_train(image_path,titlestr, report_name='test'):\n",
    "    # other_dataset = 'train' if report_name == 'test' else 'test'\n",
    "    other_dataset = 'test'\n",
    "    image_path1 = image_path+'.png'\n",
    "    image_path2 = image_path.replace(f\".{report_name}.\",f\".{other_dataset}.\")+'.png'\n",
    "\n",
    "    img1 = mpimg.imread(image_path1)\n",
    "    img2 = mpimg.imread(image_path2)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 10),constrained_layout=True)\n",
    "    ax[0].imshow(img1)\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title(report_name,fontsize=20)\n",
    "    ax[1].imshow(img2)\n",
    "    ax[1].axis('off')\n",
    "    ax[1].set_title(other_dataset,fontsize=20)\n",
    "    \n",
    "    fig.suptitle(titlestr,fontsize=24,y=0.95)\n",
    "    plt.show()\n",
    "\n",
    "dataname = params_file.split('/')[-1].split('.')[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67210add",
   "metadata": {},
   "outputs": [],
   "source": [
    "@safe_run\n",
    "def display_with_vertical_lines(df, sep_columns=None, unique_id='dataframe'):\n",
    "    \"\"\"\n",
    "    Displays a DataFrame in a Jupyter notebook with vertical lines between selected columns.\n",
    "    Applies styling only to the specified DataFrame using a unique ID.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to display.\n",
    "    sep_columns (list of int): The list of column indices where vertical lines should be drawn. \n",
    "                               The line is drawn before these column indices.\n",
    "    unique_id (str): A unique ID for the DataFrame to scope the CSS styling.\n",
    "    \"\"\"\n",
    "    # Convert DataFrame to HTML with a unique ID and include index\n",
    "    html = df.to_html(border=0, classes='dataframe', justify='left', index=True)\n",
    "    html = html.replace('<table', f'<table id=\"{unique_id}\"')\n",
    "\n",
    "    # Add styles for vertical lines with unique ID\n",
    "    style = f'''\n",
    "    <style>\n",
    "    #{unique_id} th {{\n",
    "        text-align: left;  /* Left-align column headers */\n",
    "        padding: 6px;  /* Adjust padding if necessary */\n",
    "    }}\n",
    "    #{unique_id} td {{\n",
    "        text-align: right;  /* Right-align table body cells */\n",
    "        padding: 6px;  /* Adjust padding if necessary */\n",
    "    }}\n",
    "    #{unique_id} td, #{unique_id} th {{\n",
    "        border-right: 1px solid #000;\n",
    "    }}\n",
    "    '''\n",
    "    \n",
    "    # If specific columns are selected for separation lines\n",
    "    if sep_columns is not None:\n",
    "        sep_style = \"\"\n",
    "        for col in sep_columns:\n",
    "            sep_style += f\"#{unique_id} td:nth-child({col + 1}), #{unique_id} th:nth-child({col + 1}) {{ border-right: 2px solid black !important; }}\\n\"\n",
    "        style += sep_style\n",
    "    \n",
    "    # Close style tags\n",
    "    style += \"</style>\"\n",
    "    \n",
    "    # Display the styled HTML\n",
    "    display(HTML(style + html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae775ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "@safe_run\n",
    "def display_image_with_max_width(image_path, w=1.0):\n",
    "    \"\"\"\n",
    "    Displays an image in a Jupyter notebook with a width that is a fraction of the notebook frame.\n",
    "\n",
    "    Parameters:\n",
    "    - image_path: Path to the image file.\n",
    "    - w: Fraction of the notebook frame width (between 0 and 1).\n",
    "    \"\"\"\n",
    "    # Convert w to percentage for use in HTML/CSS\n",
    "    width_percent = int(w * 100)\n",
    "\n",
    "    # Read the image file and encode it in base64\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        encoded_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    \n",
    "    # Create an HTML string to display the image with the desired max-width\n",
    "    image_html = f'<img src=\"data:image/png;base64,{encoded_image}\" style=\"max-width: {width_percent}%; height: auto;\">'\n",
    "    \n",
    "    # Display the image using HTML\n",
    "    display(HTML(image_html))\n",
    "\n",
    "@safe_run\n",
    "def display_images_grid(image_paths, w=1/3):\n",
    "    \"\"\"\n",
    "    Displays multiple images in a grid layout in a Jupyter notebook.\n",
    "    Images are displayed in rows, with each image's width being a fraction of the notebook frame.\n",
    "    Missing images are noted, and their paths are displayed as an error report.\n",
    "\n",
    "    Parameters:\n",
    "    - image_paths: List of paths to the image files.\n",
    "    - w: Fraction of the notebook frame width for each image (between 0 and 1).\n",
    "    \"\"\"\n",
    "    # Convert w to percentage for use in HTML/CSS\n",
    "    width_percent = int(w * 100)\n",
    "    \n",
    "    # Calculate the number of images per row\n",
    "    images_per_row = math.floor(1 / w)\n",
    "    \n",
    "    # Start the HTML string for the grid\n",
    "    images_html = ''\n",
    "    missing_files = []\n",
    "    \n",
    "    # Loop through the images and create rows\n",
    "    for i in range(0, len(image_paths), images_per_row):\n",
    "        # Start a new row\n",
    "        images_html += '<div style=\"display: flex; justify-content: space-between;\">'\n",
    "        \n",
    "        # Add each image in the row or leave a space if the file doesn't exist\n",
    "        for image_path in image_paths[i:i + images_per_row]:\n",
    "            if os.path.exists(image_path):\n",
    "                # Read the image file and encode it in base64\n",
    "                with open(image_path, \"rb\") as image_file:\n",
    "                    encoded_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "                \n",
    "                # Add the image HTML to the row, with max-width and height auto\n",
    "                images_html += f'<img src=\"data:image/png;base64,{encoded_image}\" style=\"max-width: {width_percent}%; height: auto;\">'\n",
    "            else:\n",
    "                # Leave an empty space and record the missing file\n",
    "                images_html += f'<div style=\"max-width: {width_percent}%; height: auto;\"></div>'\n",
    "                missing_files.append(image_path)\n",
    "        \n",
    "        # Close the div for the row\n",
    "        images_html += '</div>'\n",
    "    \n",
    "    # Display the images in a grid using HTML\n",
    "    display(HTML(images_html))\n",
    "    \n",
    "    # If there are missing files, display them as an error report\n",
    "    if missing_files:\n",
    "        error_report = '<p style=\"font-family: monospace; color: red;\">'\n",
    "        error_report += 'The following files were not found:<br>' + '<br>'.join(missing_files)\n",
    "        error_report += '</p>'\n",
    "        display(HTML(error_report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a5d78f-47c4-4bec-b008-0b032b2db039",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(HTML(f'<font size=\"6\">SRSNV pipeline report </font>'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd7365f9-f154-415b-9775-2a95d9bc6696",
   "metadata": {},
   "source": [
    "* This report contains an analysis of the SRSNV model training.\n",
    "* We train as binary classifier per SNV. \n",
    "* The probabilities are translated to quality: quality = -10*log10(probability). \n",
    "* The quality is used as a threshold for discriminating true and false variants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ed80a5",
   "metadata": {},
   "source": [
    "<!--TOC_PLACEHOLDER-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac116334",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(f'<font size=\"5\">Run Info </font>'))\n",
    "run_info_table = pd.read_hdf(srsnv_qc_h5_file, key='run_info_table') \n",
    "if isinstance(run_info_table.loc[('Docker image', '')], str):\n",
    "    run_info_table.loc[('Docker image', '')] = '/<br>'.join(run_info_table.loc[('Docker image', '')].split('/'))\n",
    "display(HTML(run_info_table.to_frame().to_html(escape=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464a59cd",
   "metadata": {},
   "source": [
    "# Summary of quality statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb191aa3",
   "metadata": {},
   "source": [
    "## Summary statistics table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4672c348",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_quality_summary_table = pd.read_hdf(srsnv_qc_h5_file, key='run_quality_summary_table')\n",
    "run_quality_summary_table.apply(signif, args=(4,)).astype(str).to_frame() # round to 4 decimal places"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbd841b",
   "metadata": {},
   "source": [
    "## SNVQ vs Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918bf6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path1 = output_LoD_plot+'.png'\n",
    "display_image_with_max_width(image_path1, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c1b818",
   "metadata": {},
   "source": [
    "We calculate the residual SNV rate as following: \n",
    "```\n",
    "error rate in test data = # errors / # bases sequenced\n",
    "```\n",
    "where:\n",
    "```\n",
    "# errors = # of single substitution snps > filter thresh\n",
    "# bases sequenced = # of bases aligned * % mapq60 * ratio_of_bases_in_coverage_range *\n",
    "                    read_filter_correction_factor * recall[threshold]\n",
    "```\n",
    "and: \n",
    "```\n",
    "# of bases aligned = mean_coverage * bases in region * downsampling factor\n",
    "downsampling factor = % of the featuremap reads sampled for test set\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cee28c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if params.get('normalization_factors_dict', None) is not None:\n",
    "    print('Normalization factors:')\n",
    "    display(pd.Series(params['normalization_factors_dict'], name='').to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae879a3",
   "metadata": {},
   "source": [
    "## SNVQ percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9effb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_quality_table = pd.read_hdf(srsnv_qc_h5_file, key='run_quality_table_display')\n",
    "display_with_vertical_lines(run_quality_table, unique_id='run_quality_table')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb2f8e5",
   "metadata": {},
   "source": [
    "## SNVQ histogram (TP reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa20406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_with_max_width(qual_histogram+'.png', 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281bc78a",
   "metadata": {},
   "source": [
    "# SNVQ and statistics per feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b5201e",
   "metadata": {},
   "source": [
    "## Categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457f1a9b",
   "metadata": {},
   "source": [
    "### SNVQ vs start/end ppmSeq tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75af1951",
   "metadata": {},
   "source": [
    "The table below present median SNVQ values on the TP (homozygous substitutions) training dataset. Numbers in square brackets are the proportion of datapoints with each start/end tag combination. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fccffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_with_max_width(qual_vs_ppmseq_tags_table+'.png', 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9645c339",
   "metadata": {},
   "source": [
    "### Quality as function of trinuc context and alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fb35c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_with_max_width(trinuc_stats_plot+'.png', 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc20873",
   "metadata": {},
   "source": [
    "## Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2db658",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = [output_qual_per_feature + f + '.png' for f in params[\"numerical_features\"]]\n",
    "display_images_grid(image_paths, w=1/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bccb99",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b5350c",
   "metadata": {},
   "source": [
    "## General training information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed6e9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_info_table = pd.read_hdf(srsnv_qc_h5_file, key='training_info_table')\n",
    "training_info_table.to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c89f62",
   "metadata": {},
   "source": [
    "## ROC AUC\n",
    "Values below are ROC AUC phred scores, i.e., $-10 \\log_{10}(1-\\text{AUC})$. NaN values indicate a problem calculating the ROC AUC score, e.g. when there are no mixed reads. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d23efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_table = pd.read_hdf(srsnv_qc_h5_file, key='roc_auc_table')\n",
    "roc_auc_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd4ba7a",
   "metadata": {},
   "source": [
    "## Logit histogram\n",
    "The logit of a prediction is defined as $$\\text{logit} = 10 \\log_{10}\\frac{p}{1-p}$$ where $p$ is the predicted probability to be True. When $p$ is close to 1, logit is close to ML_qual.\n",
    "\n",
    "The following plot presents histograms of the logits. Histograms for the predictions of each data fold are calculated separately and overlayed in the plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9379420f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_with_max_width(logit_histogram+'.png', 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e051f277",
   "metadata": {},
   "source": [
    "## ML_qual -> SNVQ mapping function\n",
    "The function that maps the models' ML_qual values to SNVQ values. Histograms of ML_qual and SNVQ are also provided, as well as the derivative $\\frac{d\\text{ML}\\_\\text{qual}}{d\\text{SNVQ}}$ (deonted 'deriv' in plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb6e11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_with_max_width(calibration_fn_with_hist+'.png', 0.35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040677d8",
   "metadata": {},
   "source": [
    "## Training progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5965a238",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_with_max_width(training_progerss_plot+'.png', 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b92541",
   "metadata": {},
   "source": [
    "# Feature importance: SHAP\n",
    "SHAP values are an estimation of how much each feature value has contributed to the model prediction, in our binary classification case, to the model's logit value. The output logit equals an overall bias term plus the sum of all features SHAP values for a given input. Large positive SHAP values \"push\" the prediction towards True, and large negative values towards False. \n",
    "\n",
    "For example, for a linear classifier (logistic regression), the logit value is $$y = \\sum_i w_i x_i,$$ where the $x_i$'s are the feature values. The SHAP value of feature $i$ for this prediction is $w_i x_i$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d8cba1",
   "metadata": {},
   "source": [
    "## Shap bar plot\n",
    "The following plot measure the importance of features by mean absolute shap values per feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2d7df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_with_max_width(SHAP_importance_plot+'.png', 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bb420e",
   "metadata": {},
   "source": [
    "## SHAP beeswarm plot\n",
    "More insight into the model's prediction is available from the beeswarm plot. This is a scatter plot of SHAP values (each point is the SHAP value for one datapoint), providing insight into how SHAP values are distributed by feature. Moreover, the colors represent the feature value at the given datapoint, revealing whether particular values tend to affect the predictions in a certain direction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007a9955",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_with_max_width(SHAP_beeswarm_plot+'.png', 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6091c7",
   "metadata": {},
   "source": [
    "The number in brackets next to categorical features refers to the appropriate colormap on the right that corresponds to the possible values of the feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b419f251",
   "metadata": {},
   "source": [
    "# Data and model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c70897",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(HTML(f'<font size=\"4\">Input parameters: </font>'))\n",
    "\n",
    "for item in params['model_parameters']:\n",
    "    print(f\"    * {item}: {params['model_parameters'][item]}\")\n",
    "\n",
    "params_for_print = [\n",
    "    'numerical_features',\n",
    "    'categorical_features_dict',\n",
    "    'train_set_size',   \n",
    "    'test_set_size',    \n",
    "]\n",
    "for p in params_for_print:    \n",
    "    if (type(params[p]) == list):\n",
    "        print(f\"    * {p}:\")\n",
    "        for pp in params[p]:\n",
    "            print(f\"        - {pp}\")\n",
    "    elif (type(params[p]) == dict):\n",
    "        print(f\"    * {p}:\")\n",
    "        for k, v in params[p].items():\n",
    "            print(f\"        - {k}: {v}\")\n",
    "    else:\n",
    "        print(f\"    * {p}: {params[p]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genomics.py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
