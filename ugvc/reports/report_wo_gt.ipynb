{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Report-Without-Ground-Truth-v1.0\" data-toc-modified-id=\"Report-Without-Ground-Truth-v1.0-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Report Without Ground Truth v1.0</a></span><ul class=\"toc-item\"><li><span><a href=\"#Input-prameters\" data-toc-modified-id=\"Input-prameters-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Input prameters</a></span></li></ul></li><li><span><a href=\"#Variants-Statistics\" data-toc-modified-id=\"Variants-Statistics-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Variants Statistics</a></span></li><li><span><a href=\"#Snp-statistics\" data-toc-modified-id=\"Snp-statistics-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Snp statistics</a></span><ul class=\"toc-item\"><li><span><a href=\"#Trinucleotide-Heatmap\" data-toc-modified-id=\"Trinucleotide-Heatmap-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Trinucleotide Heatmap</a></span></li></ul></li><li><span><a href=\"#INDEL-statistics\" data-toc-modified-id=\"INDEL-statistics-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>INDEL statistics</a></span><ul class=\"toc-item\"><li><span><a href=\"#Distribution-of-indel-lengths\" data-toc-modified-id=\"Distribution-of-indel-lengths-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Distribution of indel lengths</a></span></li><li><span><a href=\"#Insertion-Deletion-Statistics-for-h-mer-indels\" data-toc-modified-id=\"Insertion-Deletion-Statistics-for-h-mer-indels-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Insertion Deletion Statistics for h-mer indels</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Report Without Ground Truth v1.0\n",
    "## Input prameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from configparser import ConfigParser\n",
    "\n",
    "pd.options.display.float_format = lambda x: '{:,.1e}'.format(x) if x>1e6 else '{:,.1f}'.format(x)\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "configFile='no_gt_report.config'\n",
    "parser = ConfigParser()\n",
    "parser.read(configFile)\n",
    "\n",
    "no_gt_statistics_unfiltered= parser.get('NOGTReport', 'h5_statistics', fallback='no_gt_statistics_unfiltered.h5')\n",
    "no_gt_statistics_filtered = parser.get('NOGTReport', 'filtered_h5_statistics', fallback='no_gt_statistics_filtered.h5')\n",
    "no_gt_statistics_unfiltered_wgs = parser.get('NOGTReport', 'h5_statistics_wgs', fallback='no_gt_statistics_unfiltered_wgs.h5')\n",
    "no_gt_statistics_filtered_wgs = parser.get('NOGTReport', 'filtered_h5_statistics_wgs', fallback='no_gt_statistics_filtered_wgs.h5')\n",
    "\n",
    "is_somatic = parser.getboolean('NOGTReport', 'is_somatic', fallback=False)\n",
    "filtered_vcf = parser.get('NOGTReport', 'filtered_vcf',fallback='filtered_vcf.vcf.gz')\n",
    "annotation_intervals_names=parser.get('NOGTReport', 'annotation_intervals_names',fallback='annotation_intervals_names').split(',')\n",
    "interval_list = parser.get('NOGTReport', 'interval_list')\n",
    "ref_fasta = parser.get('NOGTReport', 'ref_fasta',fallback='Homo_sapiens_assembly38.fasta')\n",
    "ref_fasta_dict = parser.get('NOGTReport', 'ref_fasta_dict', fallback='Homo_sapiens_assembly38.dict')\n",
    "\n",
    "prmNames=['run_id','pipeline_version',\n",
    "          'h5_statistics', 'filtered_h5_statistics',\n",
    "          'h5_statistics_wgs', 'filtered_h5_statistics_wgs','annotation_intervals_names','is_somatic','filtered_vcf',\n",
    "          'interval_list'\n",
    "         ]\n",
    "\n",
    "prm={}\n",
    "for name in prmNames:\n",
    "    prm[name]=parser.get('NOGTReport', name)\n",
    "    \n",
    "h5outfile = parser.get('NOGTReport', 'h5_output', fallback='no_gt_report.h5')\n",
    "\n",
    "prmdf = pd.DataFrame.from_dict(prm, orient='index',columns=['value']).reindex(prmNames)\n",
    "prmdf.to_hdf(h5outfile, key=\"parameters\")\n",
    "prmdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T18:31:12.162317Z",
     "start_time": "2022-04-06T18:31:11.825997Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from os.path import join as pjoin\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from ugvc.dna.utils import revcomp\n",
    "import ugvc.vcfbed.vcftools as vcftools\n",
    "import ugvc.comparison.vcf_pipeline_utils as vcf_pipeline_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SMALL_SIZE = 12\n",
    "MEDIUM_SIZE = 18\n",
    "BIGGER_SIZE = 26\n",
    "TITLE_SIZE = 36\n",
    "FIGSIZE = (16, 8)\n",
    "GRID = True\n",
    "COLORS = [\n",
    "    \"blue\",\n",
    "    \"red\",\n",
    "    \"green\",\n",
    "    \"magenta\",\n",
    "    \"black\",\n",
    "    \"brown\",\n",
    "    \"orange\",\n",
    "    \"salmon\",\n",
    "    \"teal\",\n",
    "    \"coral\",\n",
    "    \"lime\",\n",
    "    \"purple\",\n",
    "    \"cyan\",\n",
    "    \"lavender\",\n",
    "    \"turquoise\",\n",
    "    \"darkgreen\",\n",
    "    \"tan\",\n",
    "    \"lightblue\",\n",
    "    \"pink\",\n",
    "    \"yellow\",\n",
    "    \"gold\",\n",
    "]\n",
    "\n",
    "plt.rc(\"font\", size=SMALL_SIZE)  # controls default text sizes\n",
    "plt.rc(\"axes\", titlesize=TITLE_SIZE)  # fontsize of the axes title\n",
    "plt.rc(\"axes\", labelsize=BIGGER_SIZE)  # fontsize of the x and y labels\n",
    "plt.rc(\"axes\", grid=GRID)  # is grid on\n",
    "plt.rc(\"axes\", prop_cycle=plt.cycler(color=COLORS))\n",
    "plt.rc(\"xtick\", labelsize=MEDIUM_SIZE)  # fontsize of the tick labels\n",
    "plt.rc(\"ytick\", labelsize=MEDIUM_SIZE)  # fontsize of the tick labels\n",
    "plt.rc(\"legend\", fontsize=MEDIUM_SIZE)  # legend fontsize\n",
    "plt.rc(\"figure\", titlesize=TITLE_SIZE)  # fontsize of the figure title\n",
    "plt.rc(\"figure\", figsize=FIGSIZE)  # size of the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Variants Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def metric_table_annotation(h5_path, annotation_name='none'):\n",
    "\n",
    "    JexlExpression = annotation_name\n",
    "    metric_table = pd.DataFrame(index=['nEvalVariants','nDeletions','nInsertions','nSNPs','nTi','nTv','tiTvRatio',\n",
    "                                       'SNP_to_indel_ratio','indel_novelty_rate','insertion_to_deletion_ratio'],\n",
    "                                columns=['novel','known','all'])\n",
    "    # CompOverlap\n",
    "    CompOverlap = pd.read_hdf(h5_path,'eval_CompOverlap')\n",
    "    CompOverlap[['nEvalVariants']] = CompOverlap[['nEvalVariants']].apply(lambda x : pd.to_numeric(x,errors='coerce'))\n",
    "    metric_table.loc['nEvalVariants','known']=int(CompOverlap.loc[(CompOverlap['JexlExpression']==JexlExpression) & (CompOverlap['Novelty']=='known'),'nEvalVariants'].values[0])\n",
    "    metric_table.loc['nEvalVariants','novel']=int(CompOverlap.loc[(CompOverlap['JexlExpression']==JexlExpression) & (CompOverlap['Novelty']=='novel'),'nEvalVariants'].values[0])\n",
    "    metric_table.loc['nEvalVariants','all']=int(CompOverlap.loc[(CompOverlap['JexlExpression']==JexlExpression) & (CompOverlap['Novelty']=='all'),'nEvalVariants'].values[0])\n",
    "    # CountVariants\n",
    "    CountVariants = pd.read_hdf(h5_path,'eval_CountVariants')\n",
    "    CountVariants[[\"nDeletions\",\"nInsertions\",\"nSNPs\"]] = CountVariants[[\"nDeletions\",\"nInsertions\",\"nSNPs\"]\n",
    "                                                                       ].apply(lambda x : pd.to_numeric(x,errors='coerce'))\n",
    "    metric_table.loc['nDeletions','known']=int(CountVariants.loc[(CountVariants['JexlExpression']==JexlExpression) & (CountVariants['Novelty']=='known'),'nDeletions'].values[0])\n",
    "    metric_table.loc['nDeletions','novel']=int(CountVariants.loc[(CountVariants['JexlExpression']==JexlExpression) & (CountVariants['Novelty']=='novel'),'nDeletions'].values[0])\n",
    "    metric_table.loc['nDeletions','all']=int(CountVariants.loc[(CountVariants['JexlExpression']==JexlExpression) & (CountVariants['Novelty']=='all'),'nDeletions'].values[0])\n",
    "    metric_table.loc['nInsertions','known']=int(CountVariants.loc[(CountVariants['JexlExpression']==JexlExpression) & (CountVariants['Novelty']=='known'),'nInsertions'].values[0])\n",
    "    metric_table.loc['nInsertions','novel']=int(CountVariants.loc[(CountVariants['JexlExpression']==JexlExpression) & (CountVariants['Novelty']=='novel'),'nInsertions'].values[0])\n",
    "    metric_table.loc['nInsertions','all']=int(CountVariants.loc[(CountVariants['JexlExpression']==JexlExpression) & (CountVariants['Novelty']=='all'),'nInsertions'].values[0])\n",
    "    metric_table.loc['nSNPs','known']=int(CountVariants.loc[(CountVariants['JexlExpression']==JexlExpression) & (CountVariants['Novelty']=='known'),'nSNPs'].values[0])\n",
    "    metric_table.loc['nSNPs','novel']=int(CountVariants.loc[(CountVariants['JexlExpression']==JexlExpression) & (CountVariants['Novelty']=='novel'),'nSNPs'].values[0])\n",
    "    metric_table.loc['nSNPs','all']=int(CountVariants.loc[(CountVariants['JexlExpression']==JexlExpression) & (CountVariants['Novelty']=='all'),'nSNPs'].values[0])\n",
    "    # TiTvVariantEvaluator\n",
    "    TiTvVariantEvaluator = pd.read_hdf(h5_path,'eval_TiTvVariantEvaluator')\n",
    "    TiTvVariantEvaluator[[\"nTi\",\"nTv\",\"tiTvRatio\"]] = TiTvVariantEvaluator[[\"nTi\",\"nTv\",\"tiTvRatio\"]\n",
    "                                                                       ].apply(lambda x : pd.to_numeric(x,errors='coerce'))\n",
    "    metric_table.loc['nTi','known']=int(TiTvVariantEvaluator.loc[(TiTvVariantEvaluator['JexlExpression']==JexlExpression) & (TiTvVariantEvaluator['Novelty']=='known'),'nTi'].values[0])\n",
    "    metric_table.loc['nTi','novel']=int(TiTvVariantEvaluator.loc[(TiTvVariantEvaluator['JexlExpression']==JexlExpression) & (TiTvVariantEvaluator['Novelty']=='novel'),'nTi'].values[0])\n",
    "    metric_table.loc['nTi','all']=int(TiTvVariantEvaluator.loc[(TiTvVariantEvaluator['JexlExpression']==JexlExpression) & (TiTvVariantEvaluator['Novelty']=='all'),'nTi'].values[0])\n",
    "    metric_table.loc['nTv','known']=int(TiTvVariantEvaluator.loc[(TiTvVariantEvaluator['JexlExpression']==JexlExpression) & (TiTvVariantEvaluator['Novelty']=='known'),'nTv'].values[0])\n",
    "    metric_table.loc['nTv','novel']=int(TiTvVariantEvaluator.loc[(TiTvVariantEvaluator['JexlExpression']==JexlExpression) & (TiTvVariantEvaluator['Novelty']=='novel'),'nTv'].values[0])\n",
    "    metric_table.loc['nTv','all']=int(TiTvVariantEvaluator.loc[(TiTvVariantEvaluator['JexlExpression']==JexlExpression) & (TiTvVariantEvaluator['Novelty']=='all'),'nTv'].values[0])\n",
    "    metric_table.loc['tiTvRatio','known']=float(TiTvVariantEvaluator.loc[(TiTvVariantEvaluator['JexlExpression']==JexlExpression) & (TiTvVariantEvaluator['Novelty']=='known'),'tiTvRatio'].values[0])\n",
    "    metric_table.loc['tiTvRatio','novel']=float(TiTvVariantEvaluator.loc[(TiTvVariantEvaluator['JexlExpression']==JexlExpression) & (TiTvVariantEvaluator['Novelty']=='novel'),'tiTvRatio'].values[0])\n",
    "    metric_table.loc['tiTvRatio','all']=float(TiTvVariantEvaluator.loc[(TiTvVariantEvaluator['JexlExpression']==JexlExpression) & (TiTvVariantEvaluator['Novelty']=='all'),'tiTvRatio'].values[0])\n",
    "\n",
    "    IndelSummary = pd.read_hdf(h5_path,'eval_IndelSummary')\n",
    "    IndelSummary[[\"SNP_het_to_hom_ratio\",\n",
    "                       \"SNP_to_indel_ratio\",\n",
    "                       \"indel_het_to_hom_ratio\",\n",
    "                       \"indel_novelty_rate\",\n",
    "                       \"insertion_to_deletion_ratio\"]] = IndelSummary[[\"SNP_het_to_hom_ratio\",\n",
    "                       \"SNP_to_indel_ratio\",\n",
    "                       \"indel_het_to_hom_ratio\",\n",
    "                       \"indel_novelty_rate\",\n",
    "                       \"insertion_to_deletion_ratio\"]].apply(lambda x : pd.to_numeric(x,errors='coerce'))\n",
    "    \n",
    "    metric_table.loc['SNP_to_indel_ratio','known']=float(IndelSummary.loc[(IndelSummary['JexlExpression']==JexlExpression) & (IndelSummary['Novelty']=='known'),'SNP_to_indel_ratio'].values[0])\n",
    "    metric_table.loc['SNP_to_indel_ratio','novel']=float(IndelSummary.loc[(IndelSummary['JexlExpression']==JexlExpression) & (IndelSummary['Novelty']=='novel'),'SNP_to_indel_ratio'].values[0])\n",
    "    metric_table.loc['SNP_to_indel_ratio','all']=float(IndelSummary.loc[(IndelSummary['JexlExpression']==JexlExpression) & (IndelSummary['Novelty']=='all'),'SNP_to_indel_ratio'].values[0])\n",
    "    metric_table.loc['indel_novelty_rate','known']=float(IndelSummary.loc[(IndelSummary['JexlExpression']==JexlExpression) & (IndelSummary['Novelty']=='known'),'indel_novelty_rate'].values[0])\n",
    "    metric_table.loc['indel_novelty_rate','novel']=float(IndelSummary.loc[(IndelSummary['JexlExpression']==JexlExpression) & (IndelSummary['Novelty']=='novel'),'indel_novelty_rate'].values[0])\n",
    "    metric_table.loc['indel_novelty_rate','all']=float(IndelSummary.loc[(IndelSummary['JexlExpression']==JexlExpression) & (IndelSummary['Novelty']=='all'),'indel_novelty_rate'].values[0])\n",
    "    metric_table.loc['insertion_to_deletion_ratio','known']=float(IndelSummary.loc[(IndelSummary['JexlExpression']==JexlExpression) & (IndelSummary['Novelty']=='known'),'insertion_to_deletion_ratio'].values[0])\n",
    "    metric_table.loc['insertion_to_deletion_ratio','novel']=float(IndelSummary.loc[(IndelSummary['JexlExpression']==JexlExpression) & (IndelSummary['Novelty']=='novel'),'insertion_to_deletion_ratio'].values[0])\n",
    "    metric_table.loc['insertion_to_deletion_ratio','all']=float(IndelSummary.loc[(IndelSummary['JexlExpression']==JexlExpression) & (IndelSummary['Novelty']=='all'),'insertion_to_deletion_ratio'].values[0])\n",
    "\n",
    "    if annotation_name == 'none':\n",
    "        annotation_name = 'wgs'\n",
    "    mi = pd.MultiIndex.from_tuples([(annotation_name, itm) for itm in list(metric_table.index)],names=['regions','metrics'])\n",
    "    metric_table.set_index(mi,inplace=True)\n",
    "    return metric_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def metric_table(annotation_names,h5_path, h5_path_filtered):\n",
    "    frames = []\n",
    "    for annotation_name in annotation_names:\n",
    "        cur_unfiltetred_result = metric_table_annotation(h5_path, annotation_name)\n",
    "        cur_filtered_result = metric_table_annotation(h5_path_filtered, annotation_name)\n",
    "        cur_result = pd.concat([cur_unfiltetred_result,cur_filtered_result],axis=1, keys=[\"unfiltered\",\"filtered\"])\n",
    "        frames.append(cur_result)\n",
    "    result = pd.concat(frames)\n",
    "    return result\n",
    "\n",
    "merged_df = metric_table(['none']+annotation_intervals_names,no_gt_statistics_unfiltered, no_gt_statistics_filtered)\n",
    "merged_df.to_hdf(h5outfile, key=\"variants_statistics\")\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "<ul>\n",
    "<li><b>nEvalVariants</b>- the number of variants <br></li>\n",
    "<li><b>nDeletions</b>- the number of variants determined to be deletions <br></li>\n",
    "<li><b>nInsertions</b>- the number of variants determined to be insertions <br></li>\n",
    "<li><b>nSNPs</b>- the number of variants determined to be single-nucleotide polymorphisms <br></li>\n",
    "<li><b>nTi</b>- number of transition variants (A↔G or T↔C) <br></li>\n",
    "<li><b>nTv</b>- number of transversion variants (A↔T or G↔C) <br></li>\n",
    "<li><b>SNP_to_indel_ratio</b>- n_SNPs divided by n_indels <br></li>\n",
    "<li><b>indel_novelty_rate</b>- n_novel_indels divided by n_indels<br></li>\n",
    "<li><b>insertion_to_deletion_ratio</b>- n_insertions divided by n_deletions<br></li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "if is_somatic:\n",
    "    display(Markdown(\"\"\"# Distribution of Allele fractions\n",
    "    Histogram of 100 bins of Allele fraction for the somatic data. \\n\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def af_hist_graph(filtered_af_hist, annotation_name='none'):\n",
    "    nbins = 100\n",
    "    bin_edges = pd.Series(np.arange(0,1,1/nbins))\n",
    "\n",
    "    for group in filtered_af_hist.columns:\n",
    "\n",
    "        plt.plot(bin_edges,filtered_af_hist[group]/np.sum(filtered_af_hist[group])*100, alpha=0.5, label=group, linewidth = '3')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.xlabel(\"Estimated allele fraction\")\n",
    "        plt.ylabel(\"% Variants\")\n",
    "        plt.title(f'{annotation_name} Pass filter AF histogram', fontsize=24)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if is_somatic:\n",
    "    filtered_af_hist = pd.read_hdf(no_gt_statistics_filtered_wgs,'af_hist')\n",
    "    af_hist_graph(filtered_af_hist,'wgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FDR Analysis\n",
    "\n",
    "filtered_vcf_df = vcftools.get_vcf_df(filtered_vcf)\n",
    "run_fpr = not all(filtered_vcf_df['filter'] == '') and ('fpr' in filtered_vcf_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if run_fpr:\n",
    "    display(Markdown(\"\"\"# FDR Analysis\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if run_fpr:\n",
    "    novel_vcf_df = filtered_vcf_df[filtered_vcf_df['db']!=True]\n",
    "    novel_pass_vcf_df = novel_vcf_df[novel_vcf_df['filter']=='PASS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<!--  ## MetricsCollection -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def FDR_graph(interval_size,fprs,pass_fps, ax=None,title = None,color='darkorange'):\n",
    "\n",
    "    params = {'legend.fontsize': 'x-large',\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'large',\n",
    "         'ytick.labelsize':'large'}\n",
    "    plt.rcParams.update(params)\n",
    "    if ax is None:\n",
    "        plt.figure()\n",
    "        ax = plt.gca()\n",
    "        ax.set_aspect('equal', 'datalim')\n",
    "        #ax.set_aspect('equal', 'box')\n",
    "        plt.axis('scaled')\n",
    "        ax.grid()\n",
    "        ax.rcParams.update(params)\n",
    "    plt.sca(ax)\n",
    "    \n",
    "    fprs = pd.Series(fprs).dropna()\n",
    "    pass_fprs = pd.Series(pass_fps).dropna()\n",
    "    select_size = len(fprs)\n",
    "    pass_select_size = len(pass_fprs)\n",
    "    expected_below = fprs*interval_size\n",
    "    pass_expected_below = pass_fprs*interval_size\n",
    "    actual = np.arange(select_size)\n",
    "    pass_actual = np.arange(pass_select_size)\n",
    "    plt.xlabel('Expected # FP variants', fontsize=30)\n",
    "    plt.ylabel('Observed #variants', fontsize=30)\n",
    "    plt.title(title, fontsize=30)\n",
    "    plt.rcParams['axes.labelsize'] = 30\n",
    "    plt.rcParams['axes.titlesize'] = 30\n",
    "\n",
    "    \n",
    "    plt.loglog(expected_below, expected_below,color='royalblue')\n",
    "    plt.loglog(expected_below, actual,'.',color='darkorange')\n",
    "    plt.loglog(pass_expected_below, pass_actual,'.',color='green')\n",
    "    plt.legend(labels=['Expected','All', 'Pass'])\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# interval_size 10**6\n",
    "if run_fpr:\n",
    "    from ugvc.vcfbed.interval_file import IntervalFile\n",
    "    interval_obj = IntervalFile(cmp_intervals=interval_list, ref=ref_fasta, ref_dict=ref_fasta_dict)\n",
    "    interval_size = vcf_pipeline_utils.bed_file_length(interval_obj.as_bed_file())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if run_fpr:\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(24, 8))\n",
    "    fprs= np.sort(novel_vcf_df[(novel_vcf_df['variant_type']=='snp')]['fpr']/(10**6))\n",
    "    pass_fps = np.sort(novel_pass_vcf_df[(novel_pass_vcf_df['variant_type']=='snp')]['fpr']/(10**6))\n",
    "    FDR_graph(interval_size,fprs,pass_fps,axes[0],'FDR novel snp')\n",
    "\n",
    "    fprs= np.sort(novel_vcf_df[(novel_vcf_df['variant_type']=='non-h-indel')]['fpr']/(10**6))\n",
    "    pass_fps = np.sort(novel_pass_vcf_df[(novel_pass_vcf_df['variant_type']=='non-h-indel')]['fpr']/(10**6))\n",
    "    FDR_graph(interval_size,fprs,pass_fps,axes[1],'FDR novel non-h-indel')\n",
    "\n",
    "    fprs= np.sort(novel_vcf_df[(novel_vcf_df['variant_type']=='h-indel')]['fpr']/(10**6))\n",
    "    pass_fps = np.sort(novel_pass_vcf_df[(novel_pass_vcf_df['variant_type']=='h-indel')]['fpr']/(10**6))\n",
    "    FDR_graph(interval_size,fprs,pass_fps,axes[2],'FDR novel h-indel')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Snp statistics\n",
    "Histogram for motif alterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "base_colors = {\"A\": \"b\", \"C\": \"r\", \"T\": \"y\", \"G\": \"g\"}\n",
    "dpi = 150\n",
    "\n",
    "def plot_motifs0_bars(motifs_0,ax=None, title_prefix = \"\"):\n",
    "    if ax is None:\n",
    "        plt.figure(figsize=(3, 6))\n",
    "        ax = plt.gca()\n",
    "    plt.sca(ax)\n",
    "\n",
    "    x = (motifs_0).sort_index(ascending=False)\n",
    "    \n",
    "    bbox_extra_artists = [\n",
    "        plt.title(f\"{title_prefix} {x.sum():.1E} SNPs\".replace(\"E+0\", \"E\"), fontsize=17)\n",
    "    ]\n",
    "    (x / motifs_0.sum() * 100).plot.barh(\n",
    "        color=[base_colors.get(v) for v in x.index.get_level_values(\"ref\")],\n",
    "        ax=ax,\n",
    "    )\n",
    "    plt.yticks(\n",
    "        ticks=range(6),\n",
    "        labels=[\n",
    "            f\"{ref}->{alt}\" for ref, alt in x.index.values\n",
    "        ],\n",
    "    )\n",
    "    for j, (_, row) in enumerate(x.to_frame().iterrows()):\n",
    "        bbox_extra_artists += [\n",
    "            plt.text(\n",
    "                row[\"size\"] / motifs_0.sum() * 101,\n",
    "                j + 0.03,\n",
    "                f\"{row['size']:.1E}\".replace(\"E+0\", \"E\"),\n",
    "            )\n",
    "        ]\n",
    "    plt.ylabel(\"\")\n",
    "    plt.xlabel(\"Frequency [%]\", fontsize=18)\n",
    "    # plt.xlim(0, ax.get_xlim()[1]+0.1)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    return bbox_extra_artists\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def snps_statistics_annot(no_gt_statistics_unfiltered,no_gt_statistics_filtered, annotation_name='none'):   \n",
    "    motifs = pd.read_hdf(no_gt_statistics_unfiltered,'snp_motifs')\n",
    "    filtered_motifs = pd.read_hdf(no_gt_statistics_filtered,'snp_motifs')    \n",
    "    \n",
    "    motifs_0 = motifs.reset_index()\n",
    "    motifs_0 = (\n",
    "        motifs_0.assign(ref=motifs_0[\"ref_motif\"].str.slice(1, 2))\n",
    "        .groupby([\"ref\", \"alt_1\"])\n",
    "        .agg({\"size\": \"sum\"})\n",
    "    )[\"size\"]\n",
    "\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 6))\n",
    "\n",
    "\n",
    "    plot_motifs0_bars(motifs_0, axes[0],title_prefix=annotation_name)\n",
    "\n",
    "    motifs_0 = filtered_motifs.reset_index()\n",
    "    motifs_0 = (\n",
    "        motifs_0.assign(ref=motifs_0[\"ref_motif\"].str.slice(1, 2))\n",
    "        .groupby([\"ref\", \"alt_1\"])\n",
    "        .agg({\"size\": \"sum\"})\n",
    "    )[\"size\"]\n",
    "    plot_motifs0_bars(motifs_0, axes[1], title_prefix=f\"{annotation_name}, Filter Pass\")\n",
    "\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "snps_statistics_annot(no_gt_statistics_unfiltered_wgs,no_gt_statistics_filtered_wgs,'wgs')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Trinucleotide Heatmap\n",
    "Heatmap for motif alterations in trinucleotide context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_heatmap(motifs,ax=None, title_prefix = \"\"):\n",
    "    \n",
    "    if ax is None:\n",
    "        plt.figure()\n",
    "        ax = plt.gca()\n",
    "    plt.sca(ax)\n",
    "\n",
    "    plt.title(f\"{title_prefix} Trinucleotide context\", fontsize=20)\n",
    "    \n",
    "    x = (motifs / motifs.sum()).reset_index()\n",
    "    x = x.assign(\n",
    "        ref=x[\"ref_motif\"].str.slice(1, 2),\n",
    "        alt_motif=x[\"ref_motif\"].str.slice(0, 1)\n",
    "        + x[\"alt_1\"]\n",
    "        + x[\"ref_motif\"].str.slice(2),\n",
    "        left=x[\"ref_motif\"].str.slice(0, 1),\n",
    "        right=x[\"ref_motif\"].str.slice(2),\n",
    "    )\n",
    "    x = x.assign(\n",
    "        family=x.apply(\n",
    "            lambda y: f\"{y['ref']}->{y['alt_1']}\",\n",
    "            axis=1,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    table_str = \"\\n\".join(\n",
    "        (\n",
    "            x[\"ref_motif\"]\n",
    "            + \"->\"\n",
    "            + x[\"alt_motif\"]\n",
    "            + \"  \"\n",
    "            + (x[\"size\"]).apply(lambda x: f\"{x:.1%}\")\n",
    "        )\n",
    "        .loc[x.sort_values(\"size\", ascending=False).head(12).index]\n",
    "        .values\n",
    "    )\n",
    "    x = x.pivot_table(\n",
    "        index=[\n",
    "            \"family\",\n",
    "            \"left\",\n",
    "        ],\n",
    "        columns=[\"right\"],\n",
    "        values=\"size\",\n",
    "    ).sort_index(ascending=False)\n",
    "    \n",
    "    ax.text(\n",
    "        0.25,\n",
    "        -0.15,\n",
    "        table_str,\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=16,\n",
    "        verticalalignment=\"top\",\n",
    "        bbox=dict(boxstyle=\"round\", facecolor=\"#EEEEEE\"),\n",
    "    )\n",
    "\n",
    "    bbox_extra_artists = list()\n",
    "    data = np.concatenate((x.iloc[:12, :], x.iloc[12:, :]), axis=1) * 100\n",
    "    plt.imshow(data, cmap=\"viridis\")\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.ax.get_yaxis().set_ticks(\n",
    "        range(\n",
    "            int(np.ceil(min(cbar.ax.get_yaxis().get_ticklocs()))),\n",
    "            1 + int(max(cbar.ax.get_yaxis().get_ticklocs())),\n",
    "            10 if (int(max(cbar.ax.get_yaxis().get_ticklocs()))-int(np.ceil(min(cbar.ax.get_yaxis().get_ticklocs())))>10) else 1))\n",
    "    cbar.ax.set_ylabel(\"Frequency [%]\", fontsize=24, rotation=270, labelpad=30)\n",
    "    plt.xticks(range(8), list(x.columns) + list(x.columns))\n",
    "    plt.yticks(range(12), x.iloc[:12, :].index.get_level_values(\"left\"))\n",
    "    plt.ylabel(\"Left base\")\n",
    "    plt.xlabel(\"Right base\")\n",
    "    plt.grid()\n",
    "    xlim = plt.gca().get_xlim()\n",
    "    ylim = plt.gca().get_ylim()\n",
    "    plt.plot(np.ones(2) * (xlim[0] + (xlim[1] - xlim[0]) / 2), ylim, \"-w\", linewidth=2)\n",
    "    plt.plot(xlim, np.ones(2) * (ylim[0] + (ylim[1] - ylim[0]) / 3), \"-w\", linewidth=2)\n",
    "    plt.plot(\n",
    "        xlim, np.ones(2) * (ylim[0] + (ylim[1] - ylim[0]) * 2 / 3), \"-w\", linewidth=2\n",
    "    )\n",
    "\n",
    "    X = np.repeat(\n",
    "        [\n",
    "            [\n",
    "                (xlim[0] + (xlim[1] - xlim[0]) / 4),\n",
    "                (xlim[0] + (xlim[1] - xlim[0]) * 3 / 4),\n",
    "            ]\n",
    "        ],\n",
    "        3,\n",
    "        axis=0,\n",
    "    )\n",
    "    Y = np.repeat(\n",
    "        [\n",
    "            [\n",
    "                (ylim[0] + (ylim[1] - ylim[0]) * 5 / 6),\n",
    "                (ylim[0] + (ylim[1] - ylim[0]) * 3 / 6),\n",
    "                (ylim[0] + (ylim[1] - ylim[0]) / 6),\n",
    "            ]\n",
    "        ],\n",
    "        2,\n",
    "        axis=0,\n",
    "    ).T\n",
    "    T = np.vstack(\n",
    "        (\n",
    "            x.iloc[:12:4, :].index.get_level_values(\"family\").values,\n",
    "            x.iloc[12::4, :].index.get_level_values(\"family\").values,\n",
    "        )\n",
    "    ).T\n",
    "\n",
    "    for xx, yy, tt in zip(X.flatten(), Y.flatten(), T.flatten()):\n",
    "        plt.text(xx, yy, tt, color=\"#BB5555\", fontsize=28, ha=\"center\", va=\"center\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def heatmap_annot(no_gt_statistics_unfiltered,no_gt_statistics_filtered):\n",
    "    \n",
    "    #for no_gt_statistics_unfiltered,no_gt_statistics_filtered,annotation_name in zip(no_gt_statistics_unfiltered_files,no_gt_statistics_filtered_files,annotation_intervals_names):   \n",
    "    motifs = pd.read_hdf(no_gt_statistics_unfiltered,'snp_motifs')\n",
    "    filtered_motifs = pd.read_hdf(no_gt_statistics_filtered,'snp_motifs')   \n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(17, 10))\n",
    "\n",
    "    plot_heatmap(motifs, axes[0], 'wgs')\n",
    "    plot_heatmap(filtered_motifs, axes[1], f\"wgs Filter Pass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "heatmap_annot(no_gt_statistics_unfiltered_wgs,no_gt_statistics_filtered_wgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# INDEL statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Distribution of indel lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ins_del_hete_graph_annot(known_indel,novel_indel,filtered_known_indel,filtered_novel_indel, title=None):\n",
    "    X = np.arange(20)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    \n",
    "    ax.bar(X + 0.00, known_indel, color = 'r', width = 0.20)\n",
    "    ax.bar(X + 0.20, novel_indel, color = 'mediumseagreen', width = 0.20)\n",
    "    ax.bar(X + 0.40, filtered_known_indel, color = 'purple', width = 0.20)\n",
    "    ax.bar(X + 0.60, filtered_novel_indel, color = 'g', width = 0.20)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(np.arange(0,20))\n",
    "    ax.set_xticklabels([-10,-9,-8,-7,-6,-5,-4,-3,-2,-1,1,2,3,4,5,6,7,8,9,10])\n",
    "    ax.legend(labels=['known_indel', 'novel_indel', 'filtered_known_indel', 'filtered_novel_indel'])\n",
    "    ax.set_xlabel('Indel Length')\n",
    "    \n",
    "    \n",
    "\n",
    "def ins_del_hete_graph(no_gt_statistics_unfiltered,no_gt_statistics_filtered):\n",
    "    \n",
    "    #for no_gt_statistics_unfiltered,no_gt_statistics_filtered,annotation_name in zip(no_gt_statistics_unfiltered_files,no_gt_statistics_filtered_files,annotation_intervals_names):\n",
    "        \n",
    "    IndelLengthHistogram = pd.read_hdf(no_gt_statistics_unfiltered,'eval_IndelLengthHistogram')\n",
    "    filtered_IndelLengthHistogram = pd.read_hdf(no_gt_statistics_filtered,'eval_IndelLengthHistogram')\n",
    "\n",
    "    known_indel = IndelLengthHistogram[IndelLengthHistogram['Novelty']=='known']['Freq'].astype(float)\n",
    "    novel_indel = IndelLengthHistogram[IndelLengthHistogram['Novelty']=='novel']['Freq'].astype(float)\n",
    "\n",
    "    filtered_known_indel = filtered_IndelLengthHistogram[filtered_IndelLengthHistogram['Novelty']=='known']['Freq'].astype(float)\n",
    "    filtered_novel_indel = filtered_IndelLengthHistogram[filtered_IndelLengthHistogram['Novelty']=='novel']['Freq'].astype(float)\n",
    "\n",
    "    ins_del_hete_graph_annot(known_indel,\n",
    "               novel_indel,\n",
    "               filtered_known_indel,\n",
    "               filtered_novel_indel,\n",
    "               title='wgs')\n",
    "        \n",
    "ins_del_hete_graph(no_gt_statistics_unfiltered_wgs,no_gt_statistics_filtered_wgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Insertion Deletion Statistics for h-mer indels\n",
    "Number of 1-base insretion deletions in hmer of each length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not is_somatic:\n",
    "    display(Markdown(\"\"\"## Heterozygous\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ins_del_hete_graph(ins_del, ax, title):\n",
    "    X = np.arange(12)\n",
    "    \n",
    "    ax.bar(X + 0.00, ins_del.iloc[0], color = 'r', width = 0.3)\n",
    "    ax.bar(X + 0.3, ins_del.iloc[1], color = 'mediumseagreen', width = 0.3)\n",
    "    ax.bar(X + 0.00, -ins_del.iloc[2], color = 'purple', width = 0.3)\n",
    "    ax.bar(X + 0.3, -ins_del.iloc[3], color = 'g', width = 0.3)\n",
    "\n",
    "    ax.set_title(title, fontsize=18)\n",
    "    ax.set_xticks(np.arange(0,12))\n",
    "    ax.set_xticklabels(pd.Series(np.arange(1,13)).apply(lambda x: f\"hmer {x}\"),rotation=45)\n",
    "    ax.legend(labels=['ins A', 'ins G', 'del A', 'del G'])\n",
    "    ax.set_yticks(ax.get_yticks())\n",
    "    \n",
    "    ax.set_yticklabels([abs(x).astype(int) for x in ax.get_yticks()])\n",
    "    ax.set_ylabel(\"Deletion        /       Insertion\",\n",
    "\n",
    "               loc=\"center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "annotation_name = 'wgs'    \n",
    "ins_del_hete = pd.read_hdf(no_gt_statistics_unfiltered_wgs,'ins_del_hete')\n",
    "ins_del_hete.columns = pd.Series(ins_del_hete.columns).apply(lambda x: f\"h-mer {x}\")\n",
    "filtered_ins_del_hete = pd.read_hdf(no_gt_statistics_filtered_wgs,'ins_del_hete')\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 10))\n",
    "\n",
    "ins_del_hete_graph(ins_del_hete, axes[0], f'{annotation_name} #h-mer insertions / deletions')\n",
    "ins_del_hete_graph(filtered_ins_del_hete, axes[1], f'{annotation_name} #Filter Pass h-mer insertions / deletions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not is_somatic:\n",
    "    display(Markdown(\"\"\"## Homozygous\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not is_somatic:\n",
    "    ins_del_homo = pd.read_hdf(no_gt_statistics_unfiltered_wgs,'ins_del_homo')\n",
    "    ins_del_homo.columns = pd.Series(ins_del_homo.columns).apply(lambda x: f\"h-mer {x}\")\n",
    "    filtered_ins_del_homo = pd.read_hdf(no_gt_statistics_filtered_wgs,'ins_del_homo')\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 10))\n",
    "\n",
    "    ins_del_hete_graph(ins_del_homo, axes[0], f'wgs # insertions / deletions')\n",
    "    ins_del_hete_graph(filtered_ins_del_homo, axes[1], f'wgs #Filter Pass insertions / deletions')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
